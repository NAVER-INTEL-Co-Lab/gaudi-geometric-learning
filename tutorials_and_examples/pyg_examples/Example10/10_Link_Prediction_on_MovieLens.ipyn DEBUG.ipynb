{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uh7LaSzfwcj2",
    "outputId": "08573a01-e064-4c84-8624-440ffb2a2d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT_HPU_LAZY_MODE: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
      "Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
      "Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0a0+git74cd574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(object, types.FunctionType)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the eager mode\n",
    "os.environ['PT_HPU_LAZY_MODE'] = '0'\n",
    "\n",
    "# Verify the environment variable is set\n",
    "print(f\"PT_HPU_LAZY_MODE: {os.environ['PT_HPU_LAZY_MODE']}\")\n",
    "\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "import habana_frameworks.torch.core as htcore\n",
    "\n",
    "# use rich traceback\n",
    "\n",
    "from rich import traceback\n",
    "traceback.install()\n",
    "\n",
    "device = torch.device(\"hpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vit8xKCiXAue"
   },
   "source": [
    "# Link Prediction on MovieLens\n",
    "\n",
    "This colab notebook shows how to load a set of `*.csv` files as input and construct a heterogeneous graph from it.\n",
    "We will then use this dataset as input into a [heterogeneous graph model](https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html#hgtutorial), and use it for the task of link prediction.\n",
    "A few code cells require user input to let the code run through successfully.\n",
    "If you are stuck on cells that require input, take a look at the fully filled out tutorial [here](https://medium.com/@pytorch_geometric/link-prediction-on-heterogeneous-graphs-with-pyg-6d5c29677c70).\n",
    "\n",
    "We are going to use the [MovieLens dataset](https://grouplens.org/datasets/movielens/) collected by the GroupLens research group.\n",
    "This toy dataset describes ratings and tagging activity from MovieLens.\n",
    "The dataset contains approximately 100k ratings across more than 9k movies from more than 600 users.\n",
    "We are going to use this dataset to generate two node types holding data for movies and users, respectively, and one edge type connecting users and movies, representing the relation of whether a user has rated a specific movie.\n",
    "\n",
    "The link prediction task then tries to predict missing ratings, and can, for example, be used to recommend users new movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_pshZh8Y3dw"
   },
   "source": [
    "## Heterogeneous Graph Creation\n",
    "\n",
    "First, we download the dataset to an arbitrary folder (in this case, the current directory):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ciYr7NWEv5_o",
    "outputId": "5bbe4a86-5d5b-4e42-d876-c7b58d8e030b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ./ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import download_url, extract_zip\n",
    "\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '.'), '.')\n",
    "\n",
    "movies_path = './ml-latest-small/movies.csv'\n",
    "ratings_path = './ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B89RD_evY7uu"
   },
   "source": [
    "Before we create the heterogeneous graph, letâ€™s take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6ixkcCOwCDi",
    "outputId": "4bc902aa-4707-48ef-c5f0-65a8d0f0faf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.csv:\n",
      "===========\n",
      "   movieId                                       genres\n",
      "0        1  Adventure|Animation|Children|Comedy|Fantasy\n",
      "1        2                   Adventure|Children|Fantasy\n",
      "2        3                               Comedy|Romance\n",
      "3        4                         Comedy|Drama|Romance\n",
      "4        5                                       Comedy\n",
      "\n",
      "ratings.csv:\n",
      "============\n",
      "   userId  movieId\n",
      "0       1        1\n",
      "1       1        3\n",
      "2       1        6\n",
      "3       1       47\n",
      "4       1       50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('movies.csv:')\n",
    "print('===========')\n",
    "print(pd.read_csv(movies_path)[[\"movieId\", \"genres\"]].head())\n",
    "print()\n",
    "print('ratings.csv:')\n",
    "print('============')\n",
    "print(pd.read_csv(ratings_path)[[\"userId\", \"movieId\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgXipuWTZK39"
   },
   "source": [
    "We see that the `movies.csv` file provides two useful columns: `movieId` assigns a unique identifier to each movie, while the `genres` column represent genres of the given movie.\n",
    "We can make use of this column to define a feature representation that can be easily interpreted by machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd_BJMNcwJ7k",
    "outputId": "d9c2d6b4-d968-4226-e2d6-b643683931f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Action  Adventure  Drama  Horror\n",
      "movieId                                  \n",
      "1             0          1      0       0\n",
      "2             0          1      0       0\n",
      "3             0          0      0       0\n",
      "4             0          0      1       0\n",
      "5             0          0      0       0\n"
     ]
    }
   ],
   "source": [
    "# Load the entire movie data frame into memory:\n",
    "movies_df = pd.read_csv(movies_path, index_col='movieId')\n",
    "\n",
    "# Split genres and convert into indicator variables:\n",
    "genres = movies_df['genres'].str.get_dummies('|')\n",
    "print(genres[[\"Action\", \"Adventure\", \"Drama\", \"Horror\"]].head())\n",
    "\n",
    "# Use genres as movie input features:\n",
    "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
    "assert movie_feat.size() == (9742, 20)  # 20 genres in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLaDBVP4plsS"
   },
   "source": [
    "The `ratings.csv` data connects users (as given by `userId`) and movies (as given by `movieId`).\n",
    "Due to simplicity, we do not make use of the additional `timestamp` and `rating` information.\n",
    "Here, we first read the `*.csv` file from disk, and create a mapping that maps entry IDs to a consecutive value in the range `{ 0, ..., num_rows - 1 }`.\n",
    "This is needed as we want our final data representation to be as compact as possible, *e.g.*, the representation of a movie in the first row should be accessible via `x[0]`.\n",
    "\n",
    "Afterwards, we obtain the final `edge_index` representation of shape `[2, num_ratings]` from `ratings.csv` by merging mapped user and movie indices with the raw indices given by the original data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMGYv83WzSRr",
    "outputId": "35e859ca-75cb-407e-9a7c-b0d4b7b76fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of user IDs to consecutive values:\n",
      "==========================================\n",
      "   userId  mappedID\n",
      "0       1         0\n",
      "1       2         1\n",
      "2       3         2\n",
      "3       4         3\n",
      "4       5         4\n",
      "\n",
      "Mapping of movie IDs to consecutive values:\n",
      "===========================================\n",
      "   movieId  mappedID\n",
      "0        1         0\n",
      "1        2         1\n",
      "2        3         2\n",
      "3        4         3\n",
      "4        5         4\n",
      "\n",
      "Final edge indices pointing from users to movies:\n",
      "=================================================\n",
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9462, 9463, 9503]])\n"
     ]
    }
   ],
   "source": [
    "# Load the entire ratings data frame into memory:\n",
    "ratings_df = pd.read_csv(ratings_path)\n",
    "\n",
    "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
    "unique_user_id = ratings_df['userId'].unique()\n",
    "unique_user_id = pd.DataFrame(data={\n",
    "    'userId': unique_user_id,\n",
    "    'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
    "})\n",
    "print(\"Mapping of user IDs to consecutive values:\")\n",
    "print(\"==========================================\")\n",
    "print(unique_user_id.head())\n",
    "print()\n",
    "# Create a mapping from unique movie indices to range [0, num_movie_nodes):\n",
    "unique_movie_id = pd.DataFrame(data={\n",
    "    'movieId': movies_df.index,\n",
    "    'mappedID': pd.RangeIndex(len(movies_df)),\n",
    "})\n",
    "print(\"Mapping of movie IDs to consecutive values:\")\n",
    "print(\"===========================================\")\n",
    "print(unique_movie_id.head())\n",
    "\n",
    "# Perform merge to obtain the edges from users and movies:\n",
    "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
    "                            left_on='userId', right_on='userId', how='left')\n",
    "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
    "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
    "                            left_on='movieId', right_on='movieId', how='left')\n",
    "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
    "\n",
    "# With this, we are ready to construct our `edge_index` in COO format\n",
    "# following PyG semantics:\n",
    "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
    "assert edge_index_user_to_movie.size() == (2, 100836)\n",
    "\n",
    "print()\n",
    "print(\"Final edge indices pointing from users to movies:\")\n",
    "print(\"=================================================\")\n",
    "print(edge_index_user_to_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9w9fCnjvqmd2"
   },
   "source": [
    "With this, we are ready to initialize our `HeteroData` object and pass the necessary information to it.\n",
    "Note that we also pass in a `node_id` vector to each node type in order to reconstruct the original node indices from sampled subgraphs.\n",
    "We also take care of adding reverse edges to the `HeteroData` object.\n",
    "This allows our GNN model to use both directions of the edge for message passing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_63--974srt",
    "outputId": "32fe707d-f9ac-4dca-8c7b-52bbb8ddfa07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  user={ node_id=[610] },\n",
      "  movie={\n",
      "    node_id=[9742],\n",
      "    x=[9742, 20],\n",
      "  },\n",
      "  (user, rates, movie)={ edge_index=[2, 100836] },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 100836] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "# Save node indices:\n",
    "data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
    "data[\"movie\"].node_id = torch.arange(len(movies_df))\n",
    "\n",
    "# Add the node features and edge indices:\n",
    "data[\"movie\"].x = movie_feat\n",
    "data[\"user\", \"rates\", \"movie\"].edge_index = edge_index_user_to_movie\n",
    "\n",
    "# We also need to make sure to add the reverse edges from movies to users\n",
    "# in order to let a GNN be able to pass messages in both directions.\n",
    "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "\n",
    "print(data)\n",
    "\n",
    "assert data.node_types == [\"user\", \"movie\"]\n",
    "assert data.edge_types == [(\"user\", \"rates\", \"movie\"),\n",
    "                           (\"movie\", \"rev_rates\", \"user\")]\n",
    "assert data[\"user\"].num_nodes == 610\n",
    "assert data[\"user\"].num_features == 0\n",
    "assert data[\"movie\"].num_nodes == 9742\n",
    "assert data[\"movie\"].num_features == 20\n",
    "assert data[\"user\", \"rates\", \"movie\"].num_edges == 100836\n",
    "assert data[\"movie\", \"rev_rates\", \"user\"].num_edges == 100836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QGdkLAurBq9"
   },
   "source": [
    "## Defining Edge-level Training Splits\n",
    "\n",
    "Since our data is now ready-to-be-used, we can split the ratings of users into training, validation, and test splits.\n",
    "This is needed in order to ensure that we leak no information about edges used during evaluation into the training phase.\n",
    "For this, we make use of the [`transforms.RandomLinkSplit`](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RandomLinkSplit) transformation from PyG.\n",
    "This transforms randomly divides the edges in the `(\"user\", \"rates\", \"movie\")` into training, validation and test edges.\n",
    "The `disjoint_train_ratio` parameter further separates edges in the training split into edges used for message passing (`edge_index`) and edges used for supervision (`edge_label_index`).\n",
    "Note that we also need to specify the reverse edge type `(\"movie\", \"rev_rates\", \"user\")`.\n",
    "This allows the `RandomLinkSplit` transform to drop reverse edges accordingly to not leak any information into the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rwgNwoa26Eja"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "==============\n",
      "HeteroData(\n",
      "  user={ node_id=[610] },\n",
      "  movie={\n",
      "    node_id=[9742],\n",
      "    x=[9742, 20],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 56469],\n",
      "    edge_label=[24201],\n",
      "    edge_label_index=[2, 24201],\n",
      "  },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 56469] }\n",
      ")\n",
      "\n",
      "Validation data:\n",
      "================\n",
      "HeteroData(\n",
      "  user={ node_id=[610] },\n",
      "  movie={\n",
      "    node_id=[9742],\n",
      "    x=[9742, 20],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 80670],\n",
      "    edge_label=[30249],\n",
      "    edge_label_index=[2, 30249],\n",
      "  },\n",
      "  (movie, rev_rates, user)={ edge_index=[2, 80670] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# For this, we first split the set of edges into\n",
    "# training (80%), validation (10%), and testing edges (10%).\n",
    "# Across the training edges, we use 70% of edges for message passing,\n",
    "# and 30% of edges for supervision.\n",
    "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
    "# Negative edges during training will be generated on-the-fly, so we don't want to\n",
    "# add them to the graph right away.\n",
    "# Overall, we can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,  # 10% for validation\n",
    "    num_test=0.1,  # 10% for testing\n",
    "    disjoint_train_ratio=0.3,  # 30% of training edges for supervision\n",
    "    neg_sampling_ratio=2.0,  # Fixed negative edges with a ratio of 2:1\n",
    "    add_negative_train_samples=False,  # Negative edges during training generated on-the-fly\n",
    "    edge_types=(\"user\", \"rates\", \"movie\"),\n",
    "    rev_edge_types=(\"movie\", \"rev_rates\", \"user\"),\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "print(\"Training data:\")\n",
    "print(\"==============\")\n",
    "print(train_data)\n",
    "print()\n",
    "print(\"Validation data:\")\n",
    "print(\"================\")\n",
    "print(val_data)\n",
    "\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].num_edges == 56469\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 24201\n",
    "assert train_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 56469\n",
    "# No negative edges added:\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 1\n",
    "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n",
    "\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].num_edges == 80670\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 30249\n",
    "assert val_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 80670\n",
    "# Negative edges with ratio 2:1:\n",
    "assert val_data[\"user\", \"rates\", \"movie\"].edge_label.long().bincount().tolist() == [20166, 10083]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prKLwq6RsYoh"
   },
   "source": [
    "## Defining Mini-batch Loaders\n",
    "\n",
    "We are now ready to create a mini-batch loader that will generate subgraphs that can be used as input into our GNN.\n",
    "While this step is not strictly necessary for small-scale graphs, it is absolutely necessary to apply GNNs on larger graphs that do not fit onto GPU memory otherwise.\n",
    "Here, we make use of the [`loader.LinkNeighborLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.LinkNeighborLoader) which samples multiple hops from both ends of a link and creates a subgraph from it.\n",
    "Here, `edge_label_index` serves as the \"seed links\" to start sampling from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_geometric/loader/neighbor_sampler.py\n",
    "\n",
    "from typing import Callable, List, NamedTuple, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "# from torch_geometric.typing import SparseTensor\n",
    "import random\n",
    "\n",
    "\n",
    "class EdgeIndex(NamedTuple):\n",
    "    edge_index: Tensor\n",
    "    e_id: Optional[Tensor]\n",
    "    size: Tuple[int, int]\n",
    "\n",
    "    def to(self, *args, **kwargs):\n",
    "        edge_index = self.edge_index.to(*args, **kwargs)\n",
    "        e_id = self.e_id.to(*args, **kwargs) if self.e_id is not None else None\n",
    "        return EdgeIndex(edge_index, e_id, self.size)\n",
    "\n",
    "\n",
    "# class Adj(NamedTuple):\n",
    "#     adj_t: SparseTensor\n",
    "#     e_id: Optional[Tensor]\n",
    "#     size: Tuple[int, int]\n",
    "\n",
    "#     def to(self, *args, **kwargs):\n",
    "#         adj_t = self.adj_t.to(*args, **kwargs)\n",
    "#         e_id = self.e_id.to(*args, **kwargs) if self.e_id is not None else None\n",
    "#         return Adj(adj_t, e_id, self.size)\n",
    "\n",
    "\n",
    "class DenseNeighborSampler(torch.utils.data.DataLoader):\n",
    "    r\"\"\"The neighbor sampler from the `\"Inductive Representation Learning on\n",
    "    Large Graphs\" <https://arxiv.org/abs/1706.02216>`_ paper, which allows\n",
    "    for mini-batch training of GNNs on large-scale graphs where full-batch\n",
    "    training is not feasible.\n",
    "\n",
    "    Given a GNN with :math:`L` layers and a specific mini-batch of nodes\n",
    "    :obj:`node_idx` for which we want to compute embeddings, this module\n",
    "    iteratively samples neighbors and constructs bipartite graphs that simulate\n",
    "    the actual computation flow of GNNs.\n",
    "\n",
    "    More specifically, :obj:`sizes` denotes how much neighbors we want to\n",
    "    sample for each node in each layer.\n",
    "    This module then takes in these :obj:`sizes` and iteratively samples\n",
    "    :obj:`sizes[l]` for each node involved in layer :obj:`l`.\n",
    "    In the next layer, sampling is repeated for the union of nodes that were\n",
    "    already encountered.\n",
    "    The actual computation graphs are then returned in reverse-mode, meaning\n",
    "    that we pass messages from a larger set of nodes to a smaller one, until we\n",
    "    reach the nodes for which we originally wanted to compute embeddings.\n",
    "\n",
    "    Hence, an item returned by :class:`NeighborSampler` holds the current\n",
    "    :obj:`batch_size`, the IDs :obj:`n_id` of all nodes involved in the\n",
    "    computation, and a list of bipartite graph objects via the tuple\n",
    "    :obj:`(edge_index, e_id, size)`, where :obj:`edge_index` represents the\n",
    "    bipartite edges between source and target nodes, :obj:`e_id` denotes the\n",
    "    IDs of original edges in the full graph, and :obj:`size` holds the shape\n",
    "    of the bipartite graph.\n",
    "    For each bipartite graph, target nodes are also included at the beginning\n",
    "    of the list of source nodes so that one can easily apply skip-connections\n",
    "    or add self-loops.\n",
    "\n",
    "    .. warning::\n",
    "\n",
    "        :class:`~torch_geometric.loader.NeighborSampler` is deprecated and will\n",
    "        be removed in a future release.\n",
    "        Use :class:`torch_geometric.loader.NeighborLoader` instead.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using :obj:`NeighborSampler`, see\n",
    "        `examples/reddit.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        reddit.py>`_ or\n",
    "        `examples/ogbn_products_sage.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        ogbn_products_sage.py>`_.\n",
    "\n",
    "    Args:\n",
    "        edge_index (Tensor or SparseTensor): A :obj:`torch.LongTensor` or a\n",
    "            :class:`torch_sparse.SparseTensor` that defines the underlying\n",
    "            graph connectivity/message passing flow.\n",
    "            :obj:`edge_index` holds the indices of a (sparse) symmetric\n",
    "            adjacency matrix.\n",
    "            If :obj:`edge_index` is of type :obj:`torch.LongTensor`, its shape\n",
    "            must be defined as :obj:`[2, num_edges]`, where messages from nodes\n",
    "            :obj:`edge_index[0]` are sent to nodes in :obj:`edge_index[1]`\n",
    "            (in case :obj:`flow=\"source_to_target\"`).\n",
    "            If :obj:`edge_index` is of type :class:`torch_sparse.SparseTensor`,\n",
    "            its sparse indices :obj:`(row, col)` should relate to\n",
    "            :obj:`row = edge_index[1]` and :obj:`col = edge_index[0]`.\n",
    "            The major difference between both formats is that we need to input\n",
    "            the *transposed* sparse adjacency matrix.\n",
    "        sizes ([int]): The number of neighbors to sample for each node in each\n",
    "            layer. If set to :obj:`sizes[l] = -1`, all neighbors are included\n",
    "            in layer :obj:`l`.\n",
    "        node_idx (LongTensor, optional): The nodes that should be considered\n",
    "            for creating mini-batches. If set to :obj:`None`, all nodes will be\n",
    "            considered.\n",
    "        num_nodes (int, optional): The number of nodes in the graph.\n",
    "            (default: :obj:`None`)\n",
    "        return_e_id (bool, optional): If set to :obj:`False`, will not return\n",
    "            original edge indices of sampled edges. This is only useful in case\n",
    "            when operating on graphs without edge features to save memory.\n",
    "            (default: :obj:`True`)\n",
    "        transform (callable, optional): A function/transform that takes in\n",
    "            a sampled mini-batch and returns a transformed version.\n",
    "            (default: :obj:`None`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch.utils.data.DataLoader`, such as :obj:`batch_size`,\n",
    "            :obj:`shuffle`, :obj:`drop_last` or :obj:`num_workers`.\n",
    "    \"\"\"\n",
    "    def __init__(self, edge_index: Tensor,\n",
    "                 sizes: List[int], node_idx: Optional[Tensor] = None,\n",
    "                 num_nodes: Optional[int] = None, return_e_id: bool = True,\n",
    "                 transform: Callable = None, **kwargs):\n",
    "\n",
    "        edge_index = edge_index.to('cpu')\n",
    "\n",
    "        # Remove for PyTorch Lightning:\n",
    "        kwargs.pop('dataset', None)\n",
    "        kwargs.pop('collate_fn', None)\n",
    "\n",
    "        # Save for Pytorch Lightning < 1.6:\n",
    "        self.edge_index = edge_index\n",
    "        self.node_idx = node_idx\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "        self.sizes = sizes\n",
    "        self.return_e_id = return_e_id\n",
    "        self.transform = transform\n",
    "        # self.is_sparse_tensor = isinstance(edge_index, SparseTensor)\n",
    "        self.__val__ = None\n",
    "\n",
    "        # Obtain a *transposed* `SparseTensor` instance.        \n",
    "        if (num_nodes is None and node_idx is not None\n",
    "                and node_idx.dtype == torch.bool):\n",
    "            num_nodes = node_idx.size(0)\n",
    "        if (num_nodes is None and node_idx is not None\n",
    "                and node_idx.dtype == torch.long):\n",
    "            num_nodes = max(int(edge_index.max()), int(node_idx.max())) + 1\n",
    "        if num_nodes is None:\n",
    "            num_nodes = int(edge_index.max()) + 1\n",
    "        \n",
    "        self.num_nodes = num_nodes\n",
    "        self.value = torch.arange(edge_index.size(1)) if return_e_id else None\n",
    "        self.row = edge_index[0]\n",
    "        self.col = edge_index[1]\n",
    "        self.sparse_sizes = (num_nodes, num_nodes)               \n",
    "        \n",
    "        self.adj_list = [[] for _ in range(num_nodes)]\n",
    "        self.edge_ids = [[] for _ in range(num_nodes)]\n",
    "        \n",
    "        for e_id, (src, dst) in enumerate(edge_index.t()):\n",
    "            self.adj_list[src.item()].append(dst.item())\n",
    "            if return_e_id:\n",
    "                self.edge_ids[src.item()].append(e_id)\n",
    "        \n",
    "        if node_idx is None:\n",
    "            node_idx = torch.arange(num_nodes)\n",
    "        elif node_idx.dtype == torch.bool:\n",
    "            node_idx = node_idx.nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "        super().__init__(\n",
    "            node_idx.view(-1).tolist(), collate_fn=self.sample, **kwargs)\n",
    "\n",
    "    def sample_neighbors(self, nodes: Tensor, size: int) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        \"\"\"Sample neighbors for given nodes\"\"\"\n",
    "        rows, cols, e_ids = [], [], []\n",
    "        \n",
    "        for node in nodes.tolist():\n",
    "            neighbors = self.adj_list[node]\n",
    "            if len(neighbors) > 0:\n",
    "                if size > 0:\n",
    "                    num_samples = min(size, len(neighbors))\n",
    "                    sampled_idx = random.sample(range(len(neighbors)), num_samples)\n",
    "                    sampled_neighbors = [neighbors[i] for i in sampled_idx]\n",
    "                    if self.return_e_id:\n",
    "                        sampled_e_ids = [self.edge_ids[node][i] for i in sampled_idx]\n",
    "                else:\n",
    "                    sampled_neighbors = neighbors\n",
    "                    sampled_e_ids = self.edge_ids[node] if self.return_e_id else []\n",
    "                \n",
    "                rows.extend([node] * len(sampled_neighbors))\n",
    "                cols.extend(sampled_neighbors)\n",
    "                if self.return_e_id:\n",
    "                    e_ids.extend(sampled_e_ids)\n",
    "        \n",
    "        edge_index = torch.tensor([cols, rows], dtype=torch.long)\n",
    "        e_id = torch.tensor(e_ids) if self.return_e_id else None\n",
    "        return edge_index, e_id\n",
    "\n",
    "\n",
    "    def sample(self, batch):\n",
    "        if not isinstance(batch, Tensor):\n",
    "            batch = torch.tensor(batch)\n",
    "\n",
    "        batch_size: int = len(batch)\n",
    "\n",
    "        adjs = []\n",
    "        n_id = batch\n",
    "        for size in self.sizes:\n",
    "            # adj_t, n_id = self.adj_t.sample_adj(n_id, size, replace=False)\n",
    "            edge_index, e_id = self.sample_neighbors(n_id, size)\n",
    "            \n",
    "            # Get new nodes involved\n",
    "            new_nodes = torch.unique(edge_index[0])\n",
    "            n_id = torch.unique(torch.cat([n_id, new_nodes]))\n",
    "            \n",
    "            size = (n_id.size(0), len(batch))\n",
    "            adjs.append(EdgeIndex(edge_index, e_id, size))\n",
    "\n",
    "        adjs = adjs[0] if len(adjs) == 1 else adjs[::-1]\n",
    "        out = (batch_size, n_id, adjs)\n",
    "        out = self.transform(*out) if self.transform is not None else out\n",
    "        return out\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}(sizes={self.sizes})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ops.load_library(\"/root/raw_torch_for_scatter/neighbor_sample/csrc/build/libneighbor_sample.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_geometric/sampler/neighbor_sampler.py\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import sys\n",
    "import warnings\n",
    "from typing import Callable, Dict, List, Literal, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import torch_geometric.typing\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    FeatureStore,\n",
    "    GraphStore,\n",
    "    HeteroData,\n",
    "    remote_backend_utils,\n",
    ")\n",
    "from torch_geometric.data.graph_store import EdgeLayout\n",
    "from torch_geometric.sampler import (\n",
    "    BaseSampler,\n",
    "    EdgeSamplerInput,\n",
    "    HeteroSamplerOutput,\n",
    "    NegativeSampling,\n",
    "    NodeSamplerInput,\n",
    "    SamplerOutput,\n",
    ")\n",
    "from torch_geometric.sampler.base import DataType, NumNeighbors, SubgraphType\n",
    "from torch_geometric.sampler.utils import remap_keys, to_csc, to_hetero_csc\n",
    "from torch_geometric.typing import EdgeType, NodeType, OptTensor\n",
    "\n",
    "NumNeighborsType = Union[NumNeighbors, List[int], Dict[EdgeType, List[int]]]\n",
    "\n",
    "\n",
    "class NeighborSampler(BaseSampler):\n",
    "    r\"\"\"An implementation of an in-memory (heterogeneous) neighbor sampler used\n",
    "    by :class:`~torch_geometric.loader.NeighborLoader`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Union[Data, HeteroData, Tuple[FeatureStore, GraphStore]],\n",
    "        num_neighbors: NumNeighborsType,\n",
    "        subgraph_type: Union[SubgraphType, str] = 'directional',\n",
    "        replace: bool = False,\n",
    "        disjoint: bool = False,\n",
    "        temporal_strategy: str = 'uniform',\n",
    "        time_attr: Optional[str] = None,\n",
    "        weight_attr: Optional[str] = None,\n",
    "        is_sorted: bool = False,\n",
    "        share_memory: bool = False,\n",
    "        # Deprecated:\n",
    "        directed: bool = True,\n",
    "    ):\n",
    "\n",
    "        self.data_type = DataType.from_data(data)\n",
    "\n",
    "        if self.data_type == DataType.homogeneous:\n",
    "            self.num_nodes = data.num_nodes\n",
    "\n",
    "            self.node_time: Optional[Tensor] = None\n",
    "            self.edge_time: Optional[Tensor] = None\n",
    "\n",
    "            if time_attr is not None:\n",
    "                if data.is_node_attr(time_attr):\n",
    "                    self.node_time = data[time_attr]\n",
    "                elif data.is_edge_attr(time_attr):\n",
    "                    self.edge_time = data[time_attr]\n",
    "                else:\n",
    "                    raise ValueError(\n",
    "                        f\"The time attribute '{time_attr}' is neither a \"\n",
    "                        f\"node-level or edge-level attribute\")\n",
    "\n",
    "            # Convert the graph data into CSC format for sampling:\n",
    "            self.colptr, self.row, self.perm = to_csc(\n",
    "                data, device='cpu', share_memory=share_memory,\n",
    "                is_sorted=is_sorted, src_node_time=self.node_time,\n",
    "                edge_time=self.edge_time)\n",
    "\n",
    "            if self.edge_time is not None and self.perm is not None:\n",
    "                self.edge_time = self.edge_time[self.perm]\n",
    "\n",
    "            self.edge_weight: Optional[Tensor] = None\n",
    "            if weight_attr is not None:\n",
    "                self.edge_weight = data[weight_attr]\n",
    "                if self.perm is not None:\n",
    "                    self.edge_weight = self.edge_weight[self.perm]\n",
    "\n",
    "        elif self.data_type == DataType.heterogeneous:\n",
    "            self.node_types, self.edge_types = data.metadata()\n",
    "\n",
    "            self.num_nodes = {k: data[k].num_nodes for k in self.node_types}\n",
    "\n",
    "            self.node_time: Optional[Dict[NodeType, Tensor]] = None\n",
    "            self.edge_time: Optional[Dict[EdgeType, Tensor]] = None\n",
    "\n",
    "            if time_attr is not None:\n",
    "                is_node_level_time = is_edge_level_time = False\n",
    "\n",
    "                for store in data.node_stores:\n",
    "                    if time_attr in store:\n",
    "                        is_node_level_time = True\n",
    "                for store in data.edge_stores:\n",
    "                    if time_attr in store:\n",
    "                        is_edge_level_time = True\n",
    "\n",
    "                if is_node_level_time and is_edge_level_time:\n",
    "                    raise ValueError(\n",
    "                        f\"The time attribute '{time_attr}' holds both \"\n",
    "                        f\"node-level and edge-level information\")\n",
    "\n",
    "                if not is_node_level_time and not is_edge_level_time:\n",
    "                    raise ValueError(\n",
    "                        f\"The time attribute '{time_attr}' is neither a \"\n",
    "                        f\"node-level or edge-level attribute\")\n",
    "\n",
    "                if is_node_level_time:\n",
    "                    self.node_time = data.collect(time_attr)\n",
    "                else:\n",
    "                    self.edge_time = data.collect(time_attr)\n",
    "\n",
    "            # Conversion to/from C++ string type: Since C++ cannot take\n",
    "            # dictionaries with tuples as key as input, edge type triplets need\n",
    "            # to be converted into single strings.\n",
    "            self.to_rel_type = {k: '__'.join(k) for k in self.edge_types}\n",
    "            self.to_edge_type = {v: k for k, v in self.to_rel_type.items()}\n",
    "\n",
    "            # Convert the graph data into CSC format for sampling:\n",
    "            colptr_dict, row_dict, self.perm = to_hetero_csc(\n",
    "                data, device='cpu', share_memory=share_memory,\n",
    "                is_sorted=is_sorted, node_time_dict=self.node_time,\n",
    "                edge_time_dict=self.edge_time)\n",
    "\n",
    "            self.row_dict = remap_keys(row_dict, self.to_rel_type)\n",
    "            self.colptr_dict = remap_keys(colptr_dict, self.to_rel_type)\n",
    "\n",
    "            if self.edge_time is not None:\n",
    "                for edge_type, edge_time in self.edge_time.items():\n",
    "                    if self.perm.get(edge_type, None) is not None:\n",
    "                        edge_time = edge_time[self.perm[edge_type]]\n",
    "                        self.edge_time[edge_type] = edge_time\n",
    "                self.edge_time = remap_keys(self.edge_time, self.to_rel_type)\n",
    "\n",
    "            self.edge_weight: Optional[Dict[EdgeType, Tensor]] = None\n",
    "            if weight_attr is not None:\n",
    "                self.edge_weight = data.collect(weight_attr)\n",
    "                for edge_type, edge_weight in self.edge_weight.items():\n",
    "                    if self.perm.get(edge_type, None) is not None:\n",
    "                        edge_weight = edge_weight[self.perm[edge_type]]\n",
    "                        self.edge_weight[edge_type] = edge_weight\n",
    "                self.edge_weight = remap_keys(self.edge_weight,\n",
    "                                              self.to_rel_type)\n",
    "\n",
    "        else:  # self.data_type == DataType.remote\n",
    "            feature_store, graph_store = data\n",
    "\n",
    "            # Obtain graph metadata:\n",
    "            attrs = [attr for attr in feature_store.get_all_tensor_attrs()]\n",
    "\n",
    "            edge_attrs = graph_store.get_all_edge_attrs()\n",
    "            self.edge_types = list({attr.edge_type for attr in edge_attrs})\n",
    "\n",
    "            if weight_attr is not None:\n",
    "                raise NotImplementedError(\n",
    "                    f\"'weight_attr' argument not yet supported within \"\n",
    "                    f\"'{self.__class__.__name__}' for \"\n",
    "                    f\"'(FeatureStore, GraphStore)' inputs\")\n",
    "\n",
    "            if time_attr is not None:\n",
    "                # If the `time_attr` is present, we expect that `GraphStore`\n",
    "                # holds all edges sorted by destination, and within local\n",
    "                # neighborhoods, node indices should be sorted by time.\n",
    "                # TODO (matthias, manan) Find an alternative way to ensure.\n",
    "                for edge_attr in edge_attrs:\n",
    "                    if edge_attr.layout == EdgeLayout.CSR:\n",
    "                        raise ValueError(\n",
    "                            \"Temporal sampling requires that edges are stored \"\n",
    "                            \"in either COO or CSC layout\")\n",
    "                    if not edge_attr.is_sorted:\n",
    "                        raise ValueError(\n",
    "                            \"Temporal sampling requires that edges are \"\n",
    "                            \"sorted by destination, and by source time \"\n",
    "                            \"within local neighborhoods\")\n",
    "\n",
    "                # We obtain all features with `node_attr.name=time_attr`:\n",
    "                time_attrs = [\n",
    "                    copy.copy(attr) for attr in attrs\n",
    "                    if attr.attr_name == time_attr\n",
    "                ]\n",
    "\n",
    "            if not self.is_hetero:\n",
    "                self.node_types = [None]\n",
    "                self.num_nodes = max(edge_attrs[0].size)\n",
    "                self.edge_weight: Optional[Tensor] = None\n",
    "\n",
    "                self.node_time: Optional[Tensor] = None\n",
    "                self.edge_time: Optional[Tensor] = None\n",
    "\n",
    "                if time_attr is not None:\n",
    "                    if len(time_attrs) != 1:\n",
    "                        raise ValueError(\"Temporal sampling specified but did \"\n",
    "                                         \"not find any temporal data\")\n",
    "                    time_attrs[0].index = None  # Reset index for full data.\n",
    "                    time_tensor = feature_store.get_tensor(time_attrs[0])\n",
    "                    # Currently, we determine whether to use node-level or\n",
    "                    # edge-level temporal sampling based on the attribute name.\n",
    "                    if time_attr == 'time':\n",
    "                        self.node_time = time_tensor\n",
    "                    else:\n",
    "                        self.edge_time = time_tensor\n",
    "\n",
    "                self.row, self.colptr, self.perm = graph_store.csc()\n",
    "\n",
    "            else:\n",
    "                node_types = [\n",
    "                    attr.group_name for attr in attrs\n",
    "                    if isinstance(attr.group_name, str)\n",
    "                ]\n",
    "                self.node_types = list(set(node_types))\n",
    "                self.num_nodes = {\n",
    "                    node_type: remote_backend_utils.size(*data, node_type)\n",
    "                    for node_type in self.node_types\n",
    "                }\n",
    "                self.edge_weight: Optional[Dict[EdgeType, Tensor]] = None\n",
    "\n",
    "                self.node_time: Optional[Dict[NodeType, Tensor]] = None\n",
    "                self.edge_time: Optional[Dict[EdgeType, Tensor]] = None\n",
    "\n",
    "                if time_attr is not None:\n",
    "                    for attr in time_attrs:  # Reset index for full data.\n",
    "                        attr.index = None\n",
    "\n",
    "                    time_tensors = feature_store.multi_get_tensor(time_attrs)\n",
    "                    time = {\n",
    "                        attr.group_name: time_tensor\n",
    "                        for attr, time_tensor in zip(time_attrs, time_tensors)\n",
    "                    }\n",
    "\n",
    "                    group_names = [attr.group_name for attr in time_attrs]\n",
    "                    if all([isinstance(g, str) for g in group_names]):\n",
    "                        self.node_time = time\n",
    "                    elif all([isinstance(g, tuple) for g in group_names]):\n",
    "                        self.edge_time = time\n",
    "                    else:\n",
    "                        raise ValueError(\n",
    "                            f\"Found time attribute '{time_attr}' for both \"\n",
    "                            f\"node-level and edge-level types\")\n",
    "\n",
    "                # Conversion to/from C++ string type (see above):\n",
    "                self.to_rel_type = {k: '__'.join(k) for k in self.edge_types}\n",
    "                self.to_edge_type = {v: k for k, v in self.to_rel_type.items()}\n",
    "                # Convert the graph data into CSC format for sampling:\n",
    "                row_dict, colptr_dict, self.perm = graph_store.csc()\n",
    "                self.row_dict = remap_keys(row_dict, self.to_rel_type)\n",
    "                self.colptr_dict = remap_keys(colptr_dict, self.to_rel_type)\n",
    "\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.replace = replace\n",
    "        self.subgraph_type = SubgraphType(subgraph_type)\n",
    "        self.disjoint = disjoint\n",
    "        self.temporal_strategy = temporal_strategy\n",
    "\n",
    "    @property\n",
    "    def num_neighbors(self) -> NumNeighbors:\n",
    "        return self._num_neighbors\n",
    "\n",
    "    @num_neighbors.setter\n",
    "    def num_neighbors(self, num_neighbors: NumNeighborsType):\n",
    "        if isinstance(num_neighbors, NumNeighbors):\n",
    "            self._num_neighbors = num_neighbors\n",
    "        else:\n",
    "            self._num_neighbors = NumNeighbors(num_neighbors)\n",
    "\n",
    "    @property\n",
    "    def is_hetero(self) -> bool:\n",
    "        if self.data_type == DataType.homogeneous:\n",
    "            return False\n",
    "        if self.data_type == DataType.heterogeneous:\n",
    "            return True\n",
    "\n",
    "        # self.data_type == DataType.remote\n",
    "        return self.edge_types != [None]\n",
    "\n",
    "    @property\n",
    "    def is_temporal(self) -> bool:\n",
    "        return self.node_time is not None or self.edge_time is not None\n",
    "\n",
    "    @property\n",
    "    def disjoint(self) -> bool:\n",
    "        return self._disjoint or self.is_temporal\n",
    "\n",
    "    @disjoint.setter\n",
    "    def disjoint(self, disjoint: bool):\n",
    "        self._disjoint = disjoint\n",
    "\n",
    "    # Node-based sampling #####################################################\n",
    "\n",
    "    def sample_from_nodes(\n",
    "        self,\n",
    "        inputs: NodeSamplerInput,\n",
    "    ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n",
    "        out = node_sample(inputs, self._sample)\n",
    "        if self.subgraph_type == SubgraphType.bidirectional:\n",
    "            out = out.to_bidirectional()\n",
    "        return out\n",
    "\n",
    "    # Edge-based sampling #####################################################\n",
    "\n",
    "    def sample_from_edges(\n",
    "        self,\n",
    "        inputs: EdgeSamplerInput,\n",
    "        neg_sampling: Optional[NegativeSampling] = None,\n",
    "    ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n",
    "        out = edge_sample(inputs, self._sample, self.num_nodes, self.disjoint,\n",
    "                          self.node_time, neg_sampling)\n",
    "        if self.subgraph_type == SubgraphType.bidirectional:\n",
    "            out = out.to_bidirectional()\n",
    "        return out\n",
    "\n",
    "    # Other Utilities #########################################################\n",
    "\n",
    "    @property\n",
    "    def edge_permutation(self) -> Union[OptTensor, Dict[EdgeType, OptTensor]]:\n",
    "        return self.perm\n",
    "\n",
    "    # Helper functions ########################################################\n",
    "\n",
    "    def _sample(\n",
    "        self,\n",
    "        seed: Union[Tensor, Dict[NodeType, Tensor]],\n",
    "        seed_time: Optional[Union[Tensor, Dict[NodeType, Tensor]]] = None,\n",
    "        **kwargs,\n",
    "    ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n",
    "        r\"\"\"Implements neighbor sampling by calling either :obj:`pyg-lib` (if\n",
    "        installed) or :obj:`torch-sparse` (if installed) sampling routines.\n",
    "        \"\"\"\n",
    "        if isinstance(seed, dict):  # Heterogeneous sampling:\n",
    "            if self.disjoint:\n",
    "                if self.subgraph_type == SubgraphType.induced:\n",
    "                    raise ValueError(\"'disjoint' sampling not supported \"\n",
    "                                        \"for neighbor sampling with \"\n",
    "                                        \"`subgraph_type='induced'`\")\n",
    "                else:\n",
    "                    raise ValueError(\"'disjoint' sampling not supported \"\n",
    "                                        \"for neighbor sampling via \"\n",
    "                                        \"'torch-sparse'. Please install \"\n",
    "                                        \"'pyg-lib' for improved and \"\n",
    "                                        \"optimized sampling routines.\")\n",
    "\n",
    "            out = torch.ops.torch_sparse.hetero_neighbor_sample(\n",
    "                self.node_types,\n",
    "                self.edge_types,\n",
    "                self.colptr_dict,\n",
    "                self.row_dict,\n",
    "                seed,  # seed_dict\n",
    "                self.num_neighbors.get_mapped_values(self.edge_types),\n",
    "                self.num_neighbors.num_hops,\n",
    "                self.replace,\n",
    "                self.subgraph_type != SubgraphType.induced,\n",
    "            )\n",
    "            node, row, col, edge, batch = out + (None, )\n",
    "            num_sampled_nodes = num_sampled_edges = None\n",
    "\n",
    "            if num_sampled_edges is not None:\n",
    "                num_sampled_edges = remap_keys(\n",
    "                    num_sampled_edges,\n",
    "                    self.to_edge_type,\n",
    "                )\n",
    "\n",
    "            return HeteroSamplerOutput(\n",
    "                node=node,\n",
    "                row=remap_keys(row, self.to_edge_type),\n",
    "                col=remap_keys(col, self.to_edge_type),\n",
    "                edge=remap_keys(edge, self.to_edge_type),\n",
    "                batch=batch,\n",
    "                num_sampled_nodes=num_sampled_nodes,\n",
    "                num_sampled_edges=num_sampled_edges,\n",
    "            )\n",
    "\n",
    "        else:  # Homogeneous sampling:\n",
    "            if self.disjoint:\n",
    "                raise ValueError(\"'disjoint' sampling not supported for \"\n",
    "                                    \"neighbor sampling via 'torch-sparse'. \"\n",
    "                                    \"Please install 'pyg-lib' for improved \"\n",
    "                                    \"and optimized sampling routines.\")\n",
    "\n",
    "            out = torch.ops.torch_sparse.neighbor_sample(\n",
    "                self.colptr,\n",
    "                self.row,\n",
    "                seed,  # seed\n",
    "                self.num_neighbors.get_mapped_values(),\n",
    "                self.replace,\n",
    "                self.subgraph_type != SubgraphType.induced,\n",
    "            )\n",
    "            node, row, col, edge, batch = out + (None, )\n",
    "            num_sampled_nodes = num_sampled_edges = None\n",
    "\n",
    "            return SamplerOutput(\n",
    "                node=node,\n",
    "                row=row,\n",
    "                col=col,\n",
    "                edge=edge,\n",
    "                batch=batch,\n",
    "                num_sampled_nodes=num_sampled_nodes,\n",
    "                num_sampled_edges=num_sampled_edges,\n",
    "            )\n",
    "\n",
    "\n",
    "# Sampling Utilities ##########################################################\n",
    "\n",
    "\n",
    "def node_sample(\n",
    "    inputs: NodeSamplerInput,\n",
    "    sample_fn: Callable,\n",
    ") -> Union[SamplerOutput, HeteroSamplerOutput]:\n",
    "    r\"\"\"Performs sampling from a :class:`NodeSamplerInput`, leveraging a\n",
    "    sampling function that accepts a seed and (optionally) a seed time as\n",
    "    input. Returns the output of this sampling procedure.\n",
    "    \"\"\"\n",
    "    if inputs.input_type is not None:  # Heterogeneous sampling:\n",
    "        seed = {inputs.input_type: inputs.node}\n",
    "        seed_time = None\n",
    "        if inputs.time is not None:\n",
    "            seed_time = {inputs.input_type: inputs.time}\n",
    "    else:  # Homogeneous sampling:\n",
    "        seed = inputs.node\n",
    "        seed_time = inputs.time\n",
    "\n",
    "    out = sample_fn(seed, seed_time)\n",
    "    out.metadata = (inputs.input_id, inputs.time)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def edge_sample(\n",
    "    inputs: EdgeSamplerInput,\n",
    "    sample_fn: Callable,\n",
    "    num_nodes: Union[int, Dict[NodeType, int]],\n",
    "    disjoint: bool,\n",
    "    node_time: Optional[Union[Tensor, Dict[str, Tensor]]] = None,\n",
    "    neg_sampling: Optional[NegativeSampling] = None,\n",
    ") -> Union[SamplerOutput, HeteroSamplerOutput]:\n",
    "    r\"\"\"Performs sampling from an edge sampler input, leveraging a sampling\n",
    "    function of the same signature as `node_sample`.\n",
    "    \"\"\"\n",
    "    input_id = inputs.input_id\n",
    "    src = inputs.row\n",
    "    dst = inputs.col\n",
    "    edge_label = inputs.label\n",
    "    edge_label_time = inputs.time\n",
    "    input_type = inputs.input_type\n",
    "\n",
    "    src_time = dst_time = edge_label_time\n",
    "    assert edge_label_time is None or disjoint\n",
    "\n",
    "    assert isinstance(num_nodes, (dict, int))\n",
    "    if not isinstance(num_nodes, dict):\n",
    "        num_src_nodes = num_dst_nodes = num_nodes\n",
    "    else:\n",
    "        num_src_nodes = num_nodes[input_type[0]]\n",
    "        num_dst_nodes = num_nodes[input_type[-1]]\n",
    "\n",
    "    num_pos = src.numel()\n",
    "    num_neg = 0\n",
    "\n",
    "    # Negative Sampling #######################################################\n",
    "\n",
    "    if neg_sampling is not None:\n",
    "        # When we are doing negative sampling, we append negative information\n",
    "        # of nodes/edges to `src`, `dst`, `src_time`, `dst_time`.\n",
    "        # Later on, we can easily reconstruct what belongs to positive and\n",
    "        # negative examples by slicing via `num_pos`.\n",
    "        num_neg = math.ceil(num_pos * neg_sampling.amount)\n",
    "\n",
    "        if neg_sampling.is_binary():\n",
    "            # In the \"binary\" case, we randomly sample negative pairs of nodes.\n",
    "            if isinstance(node_time, dict):\n",
    "                src_node_time = node_time.get(input_type[0])\n",
    "            else:\n",
    "                src_node_time = node_time\n",
    "\n",
    "            src_neg = neg_sample(src, neg_sampling, num_src_nodes, src_time,\n",
    "                                 src_node_time, endpoint='src')\n",
    "            src = torch.cat([src, src_neg], dim=0)\n",
    "\n",
    "            if isinstance(node_time, dict):\n",
    "                dst_node_time = node_time.get(input_type[-1])\n",
    "            else:\n",
    "                dst_node_time = node_time\n",
    "\n",
    "            dst_neg = neg_sample(dst, neg_sampling, num_dst_nodes, dst_time,\n",
    "                                 dst_node_time, endpoint='dst')\n",
    "            dst = torch.cat([dst, dst_neg], dim=0)\n",
    "\n",
    "            if edge_label is None:\n",
    "                edge_label = torch.ones(num_pos)\n",
    "            size = (num_neg, ) + edge_label.size()[1:]\n",
    "            edge_neg_label = edge_label.new_zeros(size)\n",
    "            edge_label = torch.cat([edge_label, edge_neg_label])\n",
    "\n",
    "            if edge_label_time is not None:\n",
    "                src_time = dst_time = edge_label_time.repeat(\n",
    "                    1 + math.ceil(neg_sampling.amount))[:num_pos + num_neg]\n",
    "\n",
    "        elif neg_sampling.is_triplet():\n",
    "            # In the \"triplet\" case, we randomly sample negative destinations.\n",
    "            if isinstance(node_time, dict):\n",
    "                dst_node_time = node_time.get(input_type[-1])\n",
    "            else:\n",
    "                dst_node_time = node_time\n",
    "\n",
    "            dst_neg = neg_sample(dst, neg_sampling, num_dst_nodes, dst_time,\n",
    "                                 dst_node_time, endpoint='dst')\n",
    "            dst = torch.cat([dst, dst_neg], dim=0)\n",
    "\n",
    "            assert edge_label is None\n",
    "\n",
    "            if edge_label_time is not None:\n",
    "                dst_time = edge_label_time.repeat(1 + neg_sampling.amount)\n",
    "\n",
    "    # Heterogeneous Neighborhood Sampling #####################################\n",
    "\n",
    "    if input_type is not None:\n",
    "        seed_time_dict = None\n",
    "        if input_type[0] != input_type[-1]:  # Two distinct node types:\n",
    "\n",
    "            if not disjoint:\n",
    "                src, inverse_src = src.unique(return_inverse=True)\n",
    "                dst, inverse_dst = dst.unique(return_inverse=True)\n",
    "\n",
    "            seed_dict = {input_type[0]: src, input_type[-1]: dst}\n",
    "\n",
    "            if edge_label_time is not None:  # Always disjoint.\n",
    "                seed_time_dict = {\n",
    "                    input_type[0]: src_time,\n",
    "                    input_type[-1]: dst_time,\n",
    "                }\n",
    "\n",
    "        else:  # Only a single node type: Merge both source and destination.\n",
    "\n",
    "            seed = torch.cat([src, dst], dim=0)\n",
    "\n",
    "            if not disjoint:\n",
    "                seed, inverse_seed = seed.unique(return_inverse=True)\n",
    "\n",
    "            seed_dict = {input_type[0]: seed}\n",
    "\n",
    "            if edge_label_time is not None:  # Always disjoint.\n",
    "                seed_time_dict = {\n",
    "                    input_type[0]: torch.cat([src_time, dst_time], dim=0),\n",
    "                }\n",
    "\n",
    "        out = sample_fn(seed_dict, seed_time_dict)\n",
    "\n",
    "        # Enhance `out` by label information ##################################\n",
    "        if disjoint:\n",
    "            for key, batch in out.batch.items():\n",
    "                out.batch[key] = batch % num_pos\n",
    "\n",
    "        if neg_sampling is None or neg_sampling.is_binary():\n",
    "            if disjoint:\n",
    "                if input_type[0] != input_type[-1]:\n",
    "                    edge_label_index = torch.arange(num_pos + num_neg)\n",
    "                    edge_label_index = edge_label_index.repeat(2).view(2, -1)\n",
    "                else:\n",
    "                    edge_label_index = torch.arange(2 * (num_pos + num_neg))\n",
    "                    edge_label_index = edge_label_index.view(2, -1)\n",
    "            else:\n",
    "                if input_type[0] != input_type[-1]:\n",
    "                    edge_label_index = torch.stack([\n",
    "                        inverse_src,\n",
    "                        inverse_dst,\n",
    "                    ], dim=0)\n",
    "                else:\n",
    "                    edge_label_index = inverse_seed.view(2, -1)\n",
    "\n",
    "            out.metadata = (input_id, edge_label_index, edge_label, src_time)\n",
    "\n",
    "        elif neg_sampling.is_triplet():\n",
    "            if disjoint:\n",
    "                src_index = torch.arange(num_pos)\n",
    "                if input_type[0] != input_type[-1]:\n",
    "                    dst_pos_index = torch.arange(num_pos)\n",
    "                    # `dst_neg_index` needs to be offset such that indices with\n",
    "                    # offset `num_pos` belong to the same triplet:\n",
    "                    dst_neg_index = torch.arange(\n",
    "                        num_pos, seed_dict[input_type[-1]].numel())\n",
    "                    dst_neg_index = dst_neg_index.view(-1, num_pos).t()\n",
    "                else:\n",
    "                    dst_pos_index = torch.arange(num_pos, 2 * num_pos)\n",
    "                    dst_neg_index = torch.arange(\n",
    "                        2 * num_pos, seed_dict[input_type[-1]].numel())\n",
    "                    dst_neg_index = dst_neg_index.view(-1, num_pos).t()\n",
    "            else:\n",
    "                if input_type[0] != input_type[-1]:\n",
    "                    src_index = inverse_src\n",
    "                    dst_pos_index = inverse_dst[:num_pos]\n",
    "                    dst_neg_index = inverse_dst[num_pos:]\n",
    "                else:\n",
    "                    src_index = inverse_seed[:num_pos]\n",
    "                    dst_pos_index = inverse_seed[num_pos:2 * num_pos]\n",
    "                    dst_neg_index = inverse_seed[2 * num_pos:]\n",
    "\n",
    "            dst_neg_index = dst_neg_index.view(num_pos, -1).squeeze(-1)\n",
    "\n",
    "            out.metadata = (\n",
    "                input_id,\n",
    "                src_index,\n",
    "                dst_pos_index,\n",
    "                dst_neg_index,\n",
    "                src_time,\n",
    "            )\n",
    "\n",
    "    # Homogeneous Neighborhood Sampling #######################################\n",
    "\n",
    "    else:\n",
    "\n",
    "        seed = torch.cat([src, dst], dim=0)\n",
    "        seed_time = None\n",
    "\n",
    "        if not disjoint:\n",
    "            seed, inverse_seed = seed.unique(return_inverse=True)\n",
    "\n",
    "        if edge_label_time is not None:  # Always disjoint.\n",
    "            seed_time = torch.cat([src_time, dst_time])\n",
    "\n",
    "        out = sample_fn(seed, seed_time)\n",
    "\n",
    "        # Enhance `out` by label information ##################################\n",
    "        if neg_sampling is None or neg_sampling.is_binary():\n",
    "            if disjoint:\n",
    "                out.batch = out.batch % num_pos\n",
    "                edge_label_index = torch.arange(seed.numel()).view(2, -1)\n",
    "            else:\n",
    "                edge_label_index = inverse_seed.view(2, -1)\n",
    "\n",
    "            out.metadata = (input_id, edge_label_index, edge_label, src_time)\n",
    "\n",
    "        elif neg_sampling.is_triplet():\n",
    "            if disjoint:\n",
    "                out.batch = out.batch % num_pos\n",
    "                src_index = torch.arange(num_pos)\n",
    "                dst_pos_index = torch.arange(num_pos, 2 * num_pos)\n",
    "                # `dst_neg_index` needs to be offset such that indices with\n",
    "                # offset `num_pos` belong to the same triplet:\n",
    "                dst_neg_index = torch.arange(2 * num_pos, seed.numel())\n",
    "                dst_neg_index = dst_neg_index.view(-1, num_pos).t()\n",
    "            else:\n",
    "                src_index = inverse_seed[:num_pos]\n",
    "                dst_pos_index = inverse_seed[num_pos:2 * num_pos]\n",
    "                dst_neg_index = inverse_seed[2 * num_pos:]\n",
    "            dst_neg_index = dst_neg_index.view(num_pos, -1).squeeze(-1)\n",
    "\n",
    "            out.metadata = (\n",
    "                input_id,\n",
    "                src_index,\n",
    "                dst_pos_index,\n",
    "                dst_neg_index,\n",
    "                src_time,\n",
    "            )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def neg_sample(\n",
    "    seed: Tensor,\n",
    "    neg_sampling: NegativeSampling,\n",
    "    num_nodes: int,\n",
    "    seed_time: Optional[Tensor],\n",
    "    node_time: Optional[Tensor],\n",
    "    endpoint: Literal['str', 'dst'],\n",
    ") -> Tensor:\n",
    "    num_neg = math.ceil(seed.numel() * neg_sampling.amount)\n",
    "\n",
    "    # TODO: Do not sample false negatives.\n",
    "    if node_time is None:\n",
    "        return neg_sampling.sample(num_neg, endpoint, num_nodes)\n",
    "\n",
    "    # If we are in a temporal-sampling scenario, we need to respect the\n",
    "    # timestamp of the given nodes we can use as negative examples.\n",
    "    # That is, we can only sample nodes for which `node_time <= seed_time`.\n",
    "    # For now, we use a greedy algorithm which randomly samples negative\n",
    "    # nodes and discard any which do not respect the temporal constraint.\n",
    "    # We iteratively repeat this process until we have sampled a valid node for\n",
    "    # each seed.\n",
    "    # TODO See if this greedy algorithm here can be improved.\n",
    "    assert seed_time is not None\n",
    "    num_samples = math.ceil(neg_sampling.amount)\n",
    "    seed_time = seed_time.view(1, -1).expand(num_samples, -1)\n",
    "\n",
    "    out = neg_sampling.sample(num_samples * seed.numel(), endpoint, num_nodes)\n",
    "    out = out.view(num_samples, seed.numel())\n",
    "    mask = node_time[out] > seed_time  # holds all invalid samples.\n",
    "    neg_sampling_complete = False\n",
    "    for i in range(5):  # pragma: no cover\n",
    "        num_invalid = int(mask.sum())\n",
    "        if num_invalid == 0:\n",
    "            neg_sampling_complete = True\n",
    "            break\n",
    "\n",
    "        # Greedily search for alternative negatives.\n",
    "        out[mask] = tmp = neg_sampling.sample(num_invalid, endpoint, num_nodes)\n",
    "        mask[mask.clone()] = node_time[tmp] >= seed_time[mask]\n",
    "\n",
    "    if not neg_sampling_complete:  # pragma: no cover\n",
    "        # Not much options left. In that case, we set remaining negatives\n",
    "        # to the node with minimum timestamp.\n",
    "        out[mask] = node_time.argmin()\n",
    "\n",
    "    return out.view(-1)[:num_neg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from torch_geometric.data import Data, FeatureStore, GraphStore, HeteroData\n",
    "from torch_geometric.loader.link_loader import LinkLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "# , NeighborSampler \n",
    "from torch_geometric.sampler.base import SubgraphType\n",
    "from torch_geometric.typing import EdgeType, InputEdges, OptTensor\n",
    "\n",
    "\n",
    "class LinkNeighborLoader(LinkLoader):\n",
    "    r\"\"\"A link-based data loader derived as an extension of the node-based\n",
    "    :class:`torch_geometric.loader.NeighborLoader`.\n",
    "    This loader allows for mini-batch training of GNNs on large-scale graphs\n",
    "    where full-batch training is not feasible.\n",
    "\n",
    "    More specifically, this loader first selects a sample of edges from the\n",
    "    set of input edges :obj:`edge_label_index` (which may or not be edges in\n",
    "    the original graph) and then constructs a subgraph from all the nodes\n",
    "    present in this list by sampling :obj:`num_neighbors` neighbors in each\n",
    "    iteration.\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        from torch_geometric.datasets import Planetoid\n",
    "        from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "        data = Planetoid(path, name='Cora')[0]\n",
    "\n",
    "        loader = LinkNeighborLoader(\n",
    "            data,\n",
    "            # Sample 30 neighbors for each node for 2 iterations\n",
    "            num_neighbors=[30] * 2,\n",
    "            # Use a batch size of 128 for sampling training nodes\n",
    "            batch_size=128,\n",
    "            edge_label_index=data.edge_index,\n",
    "        )\n",
    "\n",
    "        sampled_data = next(iter(loader))\n",
    "        print(sampled_data)\n",
    "        >>> Data(x=[1368, 1433], edge_index=[2, 3103], y=[1368],\n",
    "                 train_mask=[1368], val_mask=[1368], test_mask=[1368],\n",
    "                 edge_label_index=[2, 128])\n",
    "\n",
    "    It is additionally possible to provide edge labels for sampled edges, which\n",
    "    are then added to the batch:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        loader = LinkNeighborLoader(\n",
    "            data,\n",
    "            num_neighbors=[30] * 2,\n",
    "            batch_size=128,\n",
    "            edge_label_index=data.edge_index,\n",
    "            edge_label=torch.ones(data.edge_index.size(1))\n",
    "        )\n",
    "\n",
    "        sampled_data = next(iter(loader))\n",
    "        print(sampled_data)\n",
    "        >>> Data(x=[1368, 1433], edge_index=[2, 3103], y=[1368],\n",
    "                 train_mask=[1368], val_mask=[1368], test_mask=[1368],\n",
    "                 edge_label_index=[2, 128], edge_label=[128])\n",
    "\n",
    "    The rest of the functionality mirrors that of\n",
    "    :class:`~torch_geometric.loader.NeighborLoader`, including support for\n",
    "    heterogeneous graphs.\n",
    "    In particular, the data loader will add the following attributes to the\n",
    "    returned mini-batch:\n",
    "\n",
    "    * :obj:`n_id` The global node index for every sampled node\n",
    "    * :obj:`e_id` The global edge index for every sampled edge\n",
    "    * :obj:`input_id`: The global index of the :obj:`edge_label_index`\n",
    "    * :obj:`num_sampled_nodes`: The number of sampled nodes in each hop\n",
    "    * :obj:`num_sampled_edges`: The number of sampled edges in each hop\n",
    "\n",
    "    .. note::\n",
    "        Negative sampling is currently implemented in an approximate\n",
    "        way, *i.e.* negative edges may contain false negatives.\n",
    "\n",
    "    .. warning::\n",
    "        Note that the sampling scheme is independent from the edge we are\n",
    "        making a prediction for.\n",
    "        That is, by default supervision edges in :obj:`edge_label_index`\n",
    "        **will not** get masked out during sampling.\n",
    "        In case there exists an overlap between message passing edges in\n",
    "        :obj:`data.edge_index` and supervision edges in\n",
    "        :obj:`edge_label_index`, you might end up sampling an edge you are\n",
    "        making a prediction for.\n",
    "        You can generally avoid this behavior (if desired) by making\n",
    "        :obj:`data.edge_index` and :obj:`edge_label_index` two disjoint sets of\n",
    "        edges, *e.g.*, via the\n",
    "        :class:`~torch_geometric.transforms.RandomLinkSplit` transformation and\n",
    "        its :obj:`disjoint_train_ratio` argument.\n",
    "\n",
    "    Args:\n",
    "        data (Any): A :class:`~torch_geometric.data.Data`,\n",
    "            :class:`~torch_geometric.data.HeteroData`, or\n",
    "            (:class:`~torch_geometric.data.FeatureStore`,\n",
    "            :class:`~torch_geometric.data.GraphStore`) data object.\n",
    "        num_neighbors (List[int] or Dict[Tuple[str, str, str], List[int]]): The\n",
    "            number of neighbors to sample for each node in each iteration.\n",
    "            If an entry is set to :obj:`-1`, all neighbors will be included.\n",
    "            In heterogeneous graphs, may also take in a dictionary denoting\n",
    "            the amount of neighbors to sample for each individual edge type.\n",
    "        edge_label_index (Tensor or EdgeType or Tuple[EdgeType, Tensor]):\n",
    "            The edge indices for which neighbors are sampled to create\n",
    "            mini-batches.\n",
    "            If set to :obj:`None`, all edges will be considered.\n",
    "            In heterogeneous graphs, needs to be passed as a tuple that holds\n",
    "            the edge type and corresponding edge indices.\n",
    "            (default: :obj:`None`)\n",
    "        edge_label (Tensor, optional): The labels of edge indices for\n",
    "            which neighbors are sampled. Must be the same length as\n",
    "            the :obj:`edge_label_index`. If set to :obj:`None` its set to\n",
    "            `torch.zeros(...)` internally. (default: :obj:`None`)\n",
    "        edge_label_time (Tensor, optional): The timestamps for edge indices\n",
    "            for which neighbors are sampled. Must be the same length as\n",
    "            :obj:`edge_label_index`. If set, temporal sampling will be\n",
    "            used such that neighbors are guaranteed to fulfill temporal\n",
    "            constraints, *i.e.*, neighbors have an earlier timestamp than\n",
    "            the ouput edge. The :obj:`time_attr` needs to be set for this\n",
    "            to work. (default: :obj:`None`)\n",
    "        replace (bool, optional): If set to :obj:`True`, will sample with\n",
    "            replacement. (default: :obj:`False`)\n",
    "        subgraph_type (SubgraphType or str, optional): The type of the returned\n",
    "            subgraph.\n",
    "            If set to :obj:`\"directional\"`, the returned subgraph only holds\n",
    "            the sampled (directed) edges which are necessary to compute\n",
    "            representations for the sampled seed nodes.\n",
    "            If set to :obj:`\"bidirectional\"`, sampled edges are converted to\n",
    "            bidirectional edges.\n",
    "            If set to :obj:`\"induced\"`, the returned subgraph contains the\n",
    "            induced subgraph of all sampled nodes.\n",
    "            (default: :obj:`\"directional\"`)\n",
    "        disjoint (bool, optional): If set to :obj: `True`, each seed node will\n",
    "            create its own disjoint subgraph.\n",
    "            If set to :obj:`True`, mini-batch outputs will have a :obj:`batch`\n",
    "            vector holding the mapping of nodes to their respective subgraph.\n",
    "            Will get automatically set to :obj:`True` in case of temporal\n",
    "            sampling. (default: :obj:`False`)\n",
    "        temporal_strategy (str, optional): The sampling strategy when using\n",
    "            temporal sampling (:obj:`\"uniform\"`, :obj:`\"last\"`).\n",
    "            If set to :obj:`\"uniform\"`, will sample uniformly across neighbors\n",
    "            that fulfill temporal constraints.\n",
    "            If set to :obj:`\"last\"`, will sample the last `num_neighbors` that\n",
    "            fulfill temporal constraints.\n",
    "            (default: :obj:`\"uniform\"`)\n",
    "        neg_sampling (NegativeSampling, optional): The negative sampling\n",
    "            configuration.\n",
    "            For negative sampling mode :obj:`\"binary\"`, samples can be accessed\n",
    "            via the attributes :obj:`edge_label_index` and :obj:`edge_label` in\n",
    "            the respective edge type of the returned mini-batch.\n",
    "            In case :obj:`edge_label` does not exist, it will be automatically\n",
    "            created and represents a binary classification task (:obj:`0` =\n",
    "            negative edge, :obj:`1` = positive edge).\n",
    "            In case :obj:`edge_label` does exist, it has to be a categorical\n",
    "            label from :obj:`0` to :obj:`num_classes - 1`.\n",
    "            After negative sampling, label :obj:`0` represents negative edges,\n",
    "            and labels :obj:`1` to :obj:`num_classes` represent the labels of\n",
    "            positive edges.\n",
    "            Note that returned labels are of type :obj:`torch.float` for binary\n",
    "            classification (to facilitate the ease-of-use of\n",
    "            :meth:`F.binary_cross_entropy`) and of type\n",
    "            :obj:`torch.long` for multi-class classification (to facilitate the\n",
    "            ease-of-use of :meth:`F.cross_entropy`).\n",
    "            For negative sampling mode :obj:`\"triplet\"`, samples can be\n",
    "            accessed via the attributes :obj:`src_index`, :obj:`dst_pos_index`\n",
    "            and :obj:`dst_neg_index` in the respective node types of the\n",
    "            returned mini-batch.\n",
    "            :obj:`edge_label` needs to be :obj:`None` for :obj:`\"triplet\"`\n",
    "            negative sampling mode.\n",
    "            If set to :obj:`None`, no negative sampling strategy is applied.\n",
    "            (default: :obj:`None`)\n",
    "        neg_sampling_ratio (int or float, optional): The ratio of sampled\n",
    "            negative edges to the number of positive edges.\n",
    "            Deprecated in favor of the :obj:`neg_sampling` argument.\n",
    "            (default: :obj:`None`)\n",
    "        time_attr (str, optional): The name of the attribute that denotes\n",
    "            timestamps for either the nodes or edges in the graph.\n",
    "            If set, temporal sampling will be used such that neighbors are\n",
    "            guaranteed to fulfill temporal constraints, *i.e.* neighbors have\n",
    "            an earlier or equal timestamp than the center node.\n",
    "            Only used if :obj:`edge_label_time` is set. (default: :obj:`None`)\n",
    "        weight_attr (str, optional): The name of the attribute that denotes\n",
    "            edge weights in the graph.\n",
    "            If set, weighted/biased sampling will be used such that neighbors\n",
    "            are more likely to get sampled the higher their edge weights are.\n",
    "            Edge weights do not need to sum to one, but must be non-negative,\n",
    "            finite and have a non-zero sum within local neighborhoods.\n",
    "            (default: :obj:`None`)\n",
    "        transform (callable, optional): A function/transform that takes in\n",
    "            a sampled mini-batch and returns a transformed version.\n",
    "            (default: :obj:`None`)\n",
    "        transform_sampler_output (callable, optional): A function/transform\n",
    "            that takes in a :class:`torch_geometric.sampler.SamplerOutput` and\n",
    "            returns a transformed version. (default: :obj:`None`)\n",
    "        is_sorted (bool, optional): If set to :obj:`True`, assumes that\n",
    "            :obj:`edge_index` is sorted by column.\n",
    "            If :obj:`time_attr` is set, additionally requires that rows are\n",
    "            sorted according to time within individual neighborhoods.\n",
    "            This avoids internal re-sorting of the data and can improve\n",
    "            runtime and memory efficiency. (default: :obj:`False`)\n",
    "        filter_per_worker (bool, optional): If set to :obj:`True`, will filter\n",
    "            the returned data in each worker's subprocess.\n",
    "            If set to :obj:`False`, will filter the returned data in the main\n",
    "            process.\n",
    "            If set to :obj:`None`, will automatically infer the decision based\n",
    "            on whether data partially lives on the GPU\n",
    "            (:obj:`filter_per_worker=True`) or entirely on the CPU\n",
    "            (:obj:`filter_per_worker=False`).\n",
    "            There exists different trade-offs for setting this option.\n",
    "            Specifically, setting this option to :obj:`True` for in-memory\n",
    "            datasets will move all features to shared memory, which may result\n",
    "            in too many open file handles. (default: :obj:`None`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch.utils.data.DataLoader`, such as :obj:`batch_size`,\n",
    "            :obj:`shuffle`, :obj:`drop_last` or :obj:`num_workers`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Union[Data, HeteroData, Tuple[FeatureStore, GraphStore]],\n",
    "        num_neighbors: Union[List[int], Dict[EdgeType, List[int]]],\n",
    "        edge_label_index: InputEdges = None,\n",
    "        edge_label: OptTensor = None,\n",
    "        edge_label_time: OptTensor = None,\n",
    "        replace: bool = False,\n",
    "        subgraph_type: Union[SubgraphType, str] = 'directional',\n",
    "        disjoint: bool = False,\n",
    "        temporal_strategy: str = 'uniform',\n",
    "        neg_sampling: Optional[NegativeSampling] = None,\n",
    "        neg_sampling_ratio: Optional[Union[int, float]] = None,\n",
    "        time_attr: Optional[str] = None,\n",
    "        weight_attr: Optional[str] = None,\n",
    "        transform: Optional[Callable] = None,\n",
    "        transform_sampler_output: Optional[Callable] = None,\n",
    "        is_sorted: bool = False,\n",
    "        filter_per_worker: Optional[bool] = None,\n",
    "        neighbor_sampler: Optional[NeighborSampler] = None,\n",
    "        directed: bool = True,  # Deprecated.\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if (edge_label_time is not None) != (time_attr is not None):\n",
    "            raise ValueError(\n",
    "                f\"Received conflicting 'edge_label_time' and 'time_attr' \"\n",
    "                f\"arguments: 'edge_label_time' is \"\n",
    "                f\"{'set' if edge_label_time is not None else 'not set'} \"\n",
    "                f\"while 'time_attr' is \"\n",
    "                f\"{'set' if time_attr is not None else 'not set'}. \"\n",
    "                f\"Both arguments must be provided for temporal sampling.\")\n",
    "\n",
    "        if neighbor_sampler is None:\n",
    "            neighbor_sampler = NeighborSampler(\n",
    "                data,\n",
    "                num_neighbors=num_neighbors,\n",
    "                replace=replace,\n",
    "                subgraph_type=subgraph_type,\n",
    "                disjoint=disjoint,\n",
    "                temporal_strategy=temporal_strategy,\n",
    "                time_attr=time_attr,\n",
    "                weight_attr=weight_attr,\n",
    "                is_sorted=is_sorted,\n",
    "                share_memory=kwargs.get('num_workers', 0) > 0,\n",
    "                directed=directed,\n",
    "            )\n",
    "\n",
    "        super().__init__(\n",
    "            data=data,\n",
    "            link_sampler=neighbor_sampler,\n",
    "            edge_label_index=edge_label_index,\n",
    "            edge_label=edge_label,\n",
    "            edge_label_time=edge_label_time,\n",
    "            neg_sampling=neg_sampling,\n",
    "            neg_sampling_ratio=neg_sampling_ratio,\n",
    "            transform=transform,\n",
    "            transform_sampler_output=transform_sampler_output,\n",
    "            filter_per_worker=filter_per_worker,\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ogh615ka9I2c",
    "outputId": "e4b6d4d3-f59b-4f8a-9b78-a2536ed08516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  user={\n",
      "    node_id=[609],\n",
      "    n_id=[609],\n",
      "  },\n",
      "  movie={\n",
      "    node_id=[2765],\n",
      "    x=[2765, 20],\n",
      "    n_id=[2765],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 17239],\n",
      "    edge_label=[384],\n",
      "    edge_label_index=[2, 384],\n",
      "    e_id=[17239],\n",
      "    input_id=[128],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 7779],\n",
      "    e_id=[7779],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# In the first hop, we sample at most 20 neighbors.\n",
    "# In the second hop, we sample at most 10 neighbors.\n",
    "# In addition, during training, we want to sample negative edges on-the-fly with\n",
    "# a ratio of 2:1.\n",
    "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
    "# from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Define seed edges:\n",
    "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,  # Use the training data\n",
    "    num_neighbors=[20, 10],  # Sample at most 20 neighbors in the first hop and 10 in the second hop\n",
    "    neg_sampling_ratio=2.0,  # Sample negative edges on-the-fly with a ratio of 2:1\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 0\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj7biOtatAmG"
   },
   "source": [
    "## Creating a Heterogeneous Link-level GNN\n",
    "\n",
    "We are now ready to create our heterogeneous GNN.\n",
    "The GNN is responsible for learning enriched node representations from the surrounding subgraphs, which can be then used to derive edge-level predictions.\n",
    "For defining our heterogenous GNN, we make use of [`nn.SAGEConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv) and the [`nn.to_hetero()`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero) function, which transforms a GNN defined on homogeneous graphs to be applied on heterogeneous ones.\n",
    "\n",
    "In addition, we define a final link-level classifier, which simply takes both node embeddings of the link we are trying to predict, and applies a dot-product on them.\n",
    "\n",
    "As users do not have any node-level information, we choose to learn their features jointly via a `torch.nn.Embedding` layer. In order to improve the expressiveness of movie features, we do the same for movie nodes, and simply add their shallow embeddings to the pre-defined genre features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebsFf-Pr_4LF",
    "outputId": "5756285f-592d-4783-a31d-1bbccf8fd454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (movie_lin): Linear(in_features=20, out_features=64, bias=True)\n",
      "  (user_emb): Embedding(610, 64)\n",
      "  (movie_emb): Embedding(9742, 64)\n",
      "  (gnn): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
      "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        # Define a 2-layer GNN computation graph.\n",
    "        # Use a *single* `ReLU` non-linearity in-between.        \n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x\n",
    "                \n",
    "        \n",
    "\n",
    "# Our final classifier applies the dot-product between source and destination\n",
    "# node embeddings to derive edge-level predictions:\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        # Convert node embeddings to edge-level representations:\n",
    "        edge_feat_user = x_user[edge_label_index[0]]\n",
    "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # Since the dataset does not come with rich features, we also learn two\n",
    "        # embedding matrices for users and movies:\n",
    "        self.movie_lin = torch.nn.Linear(20, hidden_channels)\n",
    "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
    "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
    "\n",
    "        # Instantiate homogeneous GNN:\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "\n",
    "        # Convert GNN model into a heterogeneous variant:\n",
    "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
    "\n",
    "        self.classifier = Classifier()\n",
    "\n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        x_dict = {\n",
    "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
    "          \"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
    "        }\n",
    "\n",
    "        # `x_dict` holds feature matrices of all node types\n",
    "        # `edge_index_dict` holds all edge indices of all edge types\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"user\"],\n",
    "            x_dict[\"movie\"],\n",
    "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
    "        )\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "model = Model(hidden_channels=64)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05dfew-WuWHN"
   },
   "source": [
    "## Training a Heterogeneous Link-level GNN\n",
    "\n",
    "Training our GNN is then similar to training any PyTorch model.\n",
    "We move the model to the desired device, and initialize an optimizer that takes care of adjusting model parameters via stochastic gradient descent.\n",
    "\n",
    "The training loop then iterates over our mini-batches, applies the forward computation of the model, computes the loss from ground-truth labels and obtained predictions (here we make use of binary cross entropy), and adjusts model parameters via back-propagation and stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqLuXEcrAMru",
    "outputId": "65d515e9-00d6-48d9-92f2-2b41207e6d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cpu'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:16<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.4505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:16<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.3532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:16<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:16<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:16<00:00, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "model = Model(hidden_channels=64)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    total_loss = total_examples = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Move `sampled_data` to the respective `device`\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        \n",
    "        # TODO: Run `forward` pass of the model\n",
    "        pred = model(sampled_data)\n",
    "        \n",
    "        # TODO: Apply binary cross entropy via        \n",
    "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(pred, sampled_data[\"user\", \"rates\", \"movie\"].edge_label)\n",
    "                \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'hpu'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/190 [00:00<00:22,  8.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:19<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.4758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:20<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.3742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:19<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 0.3461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:19<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 0.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 190/190 [00:20<00:00,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.3230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "device = torch.device('hpu')\n",
    "print(f\"Device: '{device}'\")\n",
    "\n",
    "model = Model(hidden_channels=64)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "# model = torch.compile(model,backend=\"hpu_backend\")\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    total_loss = total_examples = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # TODO: Move `sampled_data` to the respective `device`\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        \n",
    "        # TODO: Run `forward` pass of the model\n",
    "        pred = model(sampled_data)\n",
    "        \n",
    "        # TODO: Apply binary cross entropy via        \n",
    "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
    "        \n",
    "        loss = F.binary_cross_entropy_with_logits(pred, sampled_data[\"user\", \"rates\", \"movie\"].edge_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq-I2xaYueF0"
   },
   "source": [
    "## Evaluating a Heterogeneous Link-level GNN\n",
    "\n",
    "After training, we evaluate our model on useen data coming from the validation set.\n",
    "For this, we define a new `LinkNeighborLoader` (which now iterates over the edges in the validation set), obtain the predictions on validation edges by running the model, and finally evaluate the performance of the model by computing the AUC score over the set of predictions and their corresponding ground-truth edges (including both positive and negative edges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIrRn9YoNllj",
    "outputId": "174894fc-fc38-4500-a022-f8232c5015b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled mini-batch:\n",
      "===================\n",
      "HeteroData(\n",
      "  user={\n",
      "    node_id=[609],\n",
      "    n_id=[609],\n",
      "  },\n",
      "  movie={\n",
      "    node_id=[2652],\n",
      "    x=[2652, 20],\n",
      "    n_id=[2652],\n",
      "  },\n",
      "  (user, rates, movie)={\n",
      "    edge_index=[2, 18960],\n",
      "    edge_label=[384],\n",
      "    edge_label_index=[2, 384],\n",
      "    e_id=[18960],\n",
      "    input_id=[384],\n",
      "  },\n",
      "  (movie, rev_rates, user)={\n",
      "    edge_index=[2, 7814],\n",
      "    e_id=[7814],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the validation seed edges:\n",
    "edge_label_index = val_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = val_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=3 * 128,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(val_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() >= 0\n",
    "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vi25Z7lFPPjc",
    "outputId": "9cdf67ca-f335-4009-b2df-769697f1c99a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [00:07<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation AUC: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "preds = []\n",
    "ground_truths = []\n",
    "for sampled_data in tqdm.tqdm(val_loader):\n",
    "    with torch.no_grad():\n",
    "        # TODO: Collect predictions and ground-truths and write them into\n",
    "        # `preds` and `ground_truths`.\n",
    "        \n",
    "        sampled_data = sampled_data.to(device)\n",
    "        pred = model(sampled_data)\n",
    "        preds.append(pred.cpu())\n",
    "        ground_truths.append(sampled_data[\"user\", \"rates\", \"movie\"].edge_label.cpu())\n",
    "\n",
    "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "auc = roc_auc_score(ground_truth, pred)\n",
    "print()\n",
    "print(f\"Validation AUC: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
