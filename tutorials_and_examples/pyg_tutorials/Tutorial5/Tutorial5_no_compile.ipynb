{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial5: Aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will override the aggregation method of the GIN convolution module of Pytorch Geometric implementing the following methods:\n",
    "\n",
    "- Principal Neighborhood Aggregation (PNA)\n",
    "- Learning Aggregation Functions (LAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT_HPU_LAZY_MODE: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
      "Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
      "Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0a0+git74cd574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(object, types.FunctionType)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the eager mode\n",
    "os.environ['PT_HPU_LAZY_MODE'] = '0'\n",
    "\n",
    "# Verify the environment variable is set\n",
    "print(f\"PT_HPU_LAZY_MODE: {os.environ['PT_HPU_LAZY_MODE']}\")\n",
    "\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "import habana_frameworks.torch.core as htcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0f500789f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUPPORTS_FUSED_EDGE_INDEX',\n",
       " 'T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_call_impl',\n",
       " '_check_input',\n",
       " '_collect',\n",
       " '_compiled_call_impl',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_edge_updater_signature',\n",
       " '_get_name',\n",
       " '_get_propagate_signature',\n",
       " '_index_select',\n",
       " '_index_select_safe',\n",
       " '_lift',\n",
       " '_load_from_state_dict',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_named_members',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_set_jittable_templates',\n",
       " '_set_size',\n",
       " '_slow_forward',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'aggregate',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'decomposed_layers',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'edge_update',\n",
       " 'edge_updater',\n",
       " 'eval',\n",
       " 'explain',\n",
       " 'explain_message',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'jittable',\n",
       " 'load_state_dict',\n",
       " 'message',\n",
       " 'message_and_aggregate',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'propagate',\n",
       " 'register_aggregate_forward_hook',\n",
       " 'register_aggregate_forward_pre_hook',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_edge_update_forward_hook',\n",
       " 'register_edge_update_forward_pre_hook',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_message_and_aggregate_forward_hook',\n",
       " 'register_message_and_aggregate_forward_pre_hook',\n",
       " 'register_message_forward_hook',\n",
       " 'register_message_forward_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_propagate_forward_hook',\n",
       " 'register_propagate_forward_pre_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'special_args',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'type',\n",
       " 'update',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(MessagePassing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the <span style='color:Blue'>aggregate</span> method, or, if you are using a sparse adjacency matrix, in the <span style='color:Blue'>message_and_aggregate</span> method. Convolutional classes in PyG extend MessagePassing, we construct our custom convoutional class extending GINConv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter operation in <span style='color:Blue'>aggregate</span>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/rusty1s/pytorch_scatter/master/docs/source/_figures/add.svg?sanitize=true\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to change torch_scatter to the raw-pytorch implementation we implemented "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('hpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter, Module, Sigmoid\n",
    "import torch\n",
    "# import torch_scatter\n",
    "from scatter_raw import scatter_add_raw as scatter_add\n",
    "from scatter_raw import broadcast\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "class AbstractLAFLayer(Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AbstractLAFLayer, self).__init__()\n",
    "        assert 'units' in kwargs or 'weights' in kwargs        \n",
    "        self.device = device\n",
    "        # self.ngpus = torch.cuda.device_count()\n",
    "        self.ngpus = 1\n",
    "        \n",
    "        if 'kernel_initializer' in kwargs.keys():\n",
    "            assert kwargs['kernel_initializer'] in [\n",
    "                'random_normal',\n",
    "                'glorot_normal',\n",
    "                'he_normal',\n",
    "                'random_uniform',\n",
    "                'glorot_uniform',\n",
    "                'he_uniform']\n",
    "            self.kernel_initializer = kwargs['kernel_initializer']\n",
    "        else:\n",
    "            self.kernel_initializer = 'random_normal'\n",
    "\n",
    "        if 'weights' in kwargs.keys():\n",
    "            self.weights = Parameter(kwargs['weights'].to(self.device), \\\n",
    "                                     requires_grad=True)\n",
    "            self.units = self.weights.shape[1]\n",
    "        else:\n",
    "            self.units = kwargs['units']\n",
    "            params = torch.empty(12, self.units, device=self.device)\n",
    "            if self.kernel_initializer == 'random_normal':\n",
    "                torch.nn.init.normal_(params)\n",
    "            elif self.kernel_initializer == 'glorot_normal':\n",
    "                torch.nn.init.xavier_normal_(params)\n",
    "            elif self.kernel_initializer == 'he_normal':\n",
    "                torch.nn.init.kaiming_normal_(params)\n",
    "            elif self.kernel_initializer == 'random_uniform':\n",
    "                torch.nn.init.uniform_(params)\n",
    "            elif self.kernel_initializer == 'glorot_uniform':\n",
    "                torch.nn.init.xavier_uniform_(params)\n",
    "            elif self.kernel_initializer == 'he_uniform':\n",
    "                torch.nn.init.kaiming_uniform_(params)\n",
    "            self.weights = Parameter(params, \\\n",
    "                                     requires_grad=True)\n",
    "        e = torch.tensor([1,-1,1,-1], dtype=torch.float32, device=self.device)\n",
    "        self.e = Parameter(e, requires_grad=False)\n",
    "        num_idx = torch.tensor([1,1,0,0], dtype=torch.float32, device=self.device).\\\n",
    "                                view(1,1,-1,1)\n",
    "        self.num_idx = Parameter(num_idx, requires_grad=False)\n",
    "        den_idx = torch.tensor([0,0,1,1], dtype=torch.float32, device=self.device).\\\n",
    "                                view(1,1,-1,1)\n",
    "        self.den_idx = Parameter(den_idx, requires_grad=False)\n",
    "\n",
    "\n",
    "class LAFLayer(AbstractLAFLayer):\n",
    "    def __init__(self, eps=1e-7, **kwargs):\n",
    "        super(LAFLayer, self).__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "    \n",
    "    def forward(self, data, index, dim=0, **kwargs):\n",
    "        eps = self.eps\n",
    "        sup = 1.0 - eps \n",
    "        e = self.e\n",
    "\n",
    "        x = torch.clamp(data, eps, sup)\n",
    "        x = torch.unsqueeze(x, -1)\n",
    "        e = e.view(1,1,-1)        \n",
    "\n",
    "        exps = (1. - e)/2. + x*e \n",
    "        exps = torch.unsqueeze(exps, -1)\n",
    "        exps = torch.pow(exps, torch.relu(self.weights[0:4]))\n",
    "\n",
    "        # scatter = torch_scatter.scatter_add(exps, index.view(-1), dim=dim)\n",
    "        \n",
    "        # scatter = scatter_add(exps, index.view(-1), dim=dim)\n",
    "        \n",
    "        scatter_res = scatter(exps, index, dim=dim, reduce='sum')\n",
    "        \n",
    "        # size = torch.tensor(exps.size())\n",
    "        # size[dim] = index.max() + 1\n",
    "        # scatter = torch.zeros(*size, dtype=exps.dtype, device=exps.device)\n",
    "        # index_expand = broadcast(index, exps, dim)\n",
    "        # scatter.scatter_add_(dim, index_expand, exps)\n",
    "                \n",
    "        scatter_res = torch.clamp(scatter_res, eps)\n",
    "\n",
    "        sqrt = torch.pow(scatter_res, torch.relu(self.weights[4:8]))\n",
    "        alpha_beta = self.weights[8:12].view(1,1,4,-1)\n",
    "        terms = sqrt * alpha_beta\n",
    "\n",
    "        num = torch.sum(terms * self.num_idx, dim=2)\n",
    "        den = torch.sum(terms * self.den_idx, dim=2)\n",
    "        \n",
    "        multiplier = 2.0*torch.clamp(torch.sign(den), min=0.0) - 1.0\n",
    "\n",
    "        den = torch.where((den < eps) & (den > -eps), multiplier*eps, den)\n",
    "\n",
    "        res = num / den\n",
    "        return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GINConv\n",
    "from torch.nn import Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAF Aggregation Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"laf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINLAFConv(GINConv):\n",
    "    def __init__(self, nn, units=1, node_dim=32, **kwargs):\n",
    "        super(GINLAFConv, self).__init__(nn, **kwargs)\n",
    "        self.laf = LAFLayer(units=units, kernel_initializer='random_uniform')\n",
    "        self.mlp = torch.nn.Linear(node_dim*units, node_dim)\n",
    "        self.dim = node_dim\n",
    "        self.units = units\n",
    "    \n",
    "    def aggregate(self, inputs, index):\n",
    "        x = torch.sigmoid(inputs)\n",
    "        x = self.laf(x, index)\n",
    "        x = x.view((-1, self.dim * self.units))\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNA Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pna.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scatter_raw import (\n",
    "    scatter_add_raw as scatter_add,\n",
    "    scatter_max_raw as scatter_max,\n",
    "    scatter_mean_raw as scatter_mean\n",
    ")\n",
    "\n",
    "class GINPNAConv(GINConv):\n",
    "    def __init__(self, nn, node_dim=32, **kwargs):\n",
    "        super(GINPNAConv, self).__init__(nn, **kwargs)\n",
    "        self.mlp = torch.nn.Linear(node_dim*12, node_dim)\n",
    "        self.delta = 2.5749\n",
    "    \n",
    "    def aggregate(self, inputs, index):\n",
    "        sums = scatter_add(inputs, index, dim=0)\n",
    "        maxs = scatter_max(inputs, index, dim=0)[0]\n",
    "        means = scatter_mean(inputs, index, dim=0)\n",
    "        var = torch.relu(scatter_mean(inputs ** 2, index, dim=0) - means ** 2)\n",
    "        \n",
    "        aggrs = [sums, maxs, means, var]\n",
    "        c_idx = index.bincount().float().view(-1, 1)\n",
    "        l_idx = torch.log(c_idx + 1.)\n",
    "        \n",
    "        amplification_scaler = [c_idx / self.delta * a for a in aggrs]\n",
    "        attenuation_scaler = [self.delta / c_idx * a for a in aggrs]\n",
    "        combinations = torch.cat(aggrs+ amplification_scaler+ attenuation_scaler, dim=1)\n",
    "        x = self.mlp(combinations)\n",
    "    \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing, SAGEConv, GINConv, global_add_pool\n",
    "# import torch_scatter\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "import os.path as osp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "path = osp.join('./', 'data', 'TU')\n",
    "dataset = TUDataset(path, name='MUTAG').shuffle()\n",
    "test_dataset = dataset[:len(dataset) // 10]\n",
    "train_dataset = dataset[len(dataset) // 10:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LAFNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LAFNet, self).__init__()\n",
    "\n",
    "        num_features = dataset.num_features\n",
    "        dim = 32\n",
    "        units = 3\n",
    "        \n",
    "        nn1 = Sequential(Linear(num_features, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv1 = GINLAFConv(nn1, units=units, node_dim=num_features)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv2 = GINLAFConv(nn2, units=units, node_dim=dim)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv3 = GINLAFConv(nn3, units=units, node_dim=dim)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv4 = GINLAFConv(nn4, units=units, node_dim=dim)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv5 = GINLAFConv(nn5, units=units, node_dim=dim)\n",
    "        self.bn5 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.fc1 = Linear(dim, dim)\n",
    "        self.fc2 = Linear(dim, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "        x = self.bn5(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PNANet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PNANet, self).__init__()\n",
    "\n",
    "        num_features = dataset.num_features\n",
    "        dim = 32\n",
    "\n",
    "        nn1 = Sequential(Linear(num_features, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv1 = GINPNAConv(nn1, node_dim=num_features)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv2 = GINPNAConv(nn2, node_dim=dim)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv3 = GINPNAConv(nn3, node_dim=dim)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv4 = GINPNAConv(nn4, node_dim=dim)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv5 = GINPNAConv(nn5, node_dim=dim)\n",
    "        self.bn5 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.fc1 = Linear(dim, dim)\n",
    "        self.fc2 = Linear(dim, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "        x = self.bn5(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GINNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GINNet, self).__init__()\n",
    "\n",
    "        num_features = dataset.num_features\n",
    "        dim = 32\n",
    "\n",
    "        nn1 = Sequential(Linear(num_features, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn2 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn3 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv3 = GINConv(nn3)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn4 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv4 = GINConv(nn4)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        nn5 = Sequential(Linear(dim, dim), ReLU(), Linear(dim, dim))\n",
    "        self.conv5 = GINConv(nn5)\n",
    "        self.bn5 = torch.nn.BatchNorm1d(dim)\n",
    "\n",
    "        self.fc1 = Linear(dim, dim)\n",
    "        self.fc2 = Linear(dim, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(self.conv5(x, edge_index))\n",
    "        x = self.bn5(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 0\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_CACHE_FOLDER_DELETE = 0\n",
      " PT_HPU_RECIPE_CACHE_CONFIG = \n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      " PT_HPU_EAGER_PIPELINE_ENABLE = 1\n",
      " PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1\n",
      "---------------------------: System Configuration :---------------------------\n",
      "Num CPU Cores : 160\n",
      "CPU RAM       : 2113407800 KB\n",
      "------------------------------------------------------------------------------\n",
      "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:768: UserWarning: aten::dropout: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /npu-stack/pytorch-fork/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:63.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">48</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>train_loss = train(epoch)                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.inference_mode():                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model.eval()                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>48 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>train_acc = test(train_loader)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>test_acc = test(test_loader)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'Epoch: {:03d}, Train Loss: {:.7f}, '</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">'Train Acc: {:.7f}, Test Acc: {:.7f}'</span>.format(epoch, train_loss,                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">test</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>correct = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> data <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> loader:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data = data.to(device)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>35 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = model(data.x, data.edge_index, data.batch)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>pred = output.max(dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>correct += pred.eq(data.y).sum().item()                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> correct / <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(loader.dataset)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1556</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrapped_call_impl</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1553 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1554 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1555 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1556 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_impl(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1557 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1558 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1559 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>forward_call = (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._slow_forward <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._C._get_tracing_state() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fo  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1565</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1562 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1563 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1564 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1565 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1566 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1568 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>result = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">32 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x, edge_index, batch):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">33 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = F.relu(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.conv1(x, edge_index))                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">34 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bn1(x)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>35 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = F.relu(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.conv2(x, edge_index))                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bn2(x)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = F.relu(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.conv3(x, edge_index))                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">38 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bn3(x)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1556</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrapped_call_impl</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1553 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1554 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1555 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1556 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_impl(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1557 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1558 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1559 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>forward_call = (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._slow_forward <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._C._get_tracing_state() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fo  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1565</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1562 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1563 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1564 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1565 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1566 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1568 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>result = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">gin_conv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">84</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>x = (x, x)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 82 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 83 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># propagate_type: (x: OptPairTensor)</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 84 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>out = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.propagate(edge_index, x=x, size=size)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 85 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 86 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x_r = x[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 87 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> x_r <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">message_passing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">541</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">propagate</span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 538 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> res <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 539 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>aggr_kwargs = res[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(res, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">tuple</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> res           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 540 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 541 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>out = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.aggregate(out, **aggr_kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 542 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 543 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> hook <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._aggregate_forward_hooks.values():                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>res = hook(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, (aggr_kwargs, ), out)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aggregate</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aggregate</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs, index):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = torch.sigmoid(inputs)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>11 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.laf(x, index)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = x.view((-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dim * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.units))                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>x = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mlp(x)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> x                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1556</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_wrapped_call_impl</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1553 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1554 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._compiled_call_impl(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1555 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1556 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_impl(*args, **kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1557 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1558 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1559 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>forward_call = (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._slow_forward <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._C._get_tracing_state() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fo  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1565</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1562 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1563 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1564 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1565 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1566 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1568 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>result = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">82</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># scatter = scatter_add(exps, index.view(-1), dim=dim)</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 82 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>scatter_res = scatter(exps, index, dim=dim, reduce=<span style=\"color: #808000; text-decoration-color: #808000\">'sum'</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 83 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 84 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># size = torch.tensor(exps.size())</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 85 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># size[dim] = index.max() + 1</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_scatter.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">53</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">scatter</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │    </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>src.dim()<span style=\"color: #808080; text-decoration-color: #808080\"> </span>-<span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">} (got {</span>dim<span style=\"color: #808000; text-decoration-color: #808000\">})\"</span>)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dim_size <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 53 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>dim_size = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(index.max()) + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> index.numel() &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 55 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># For now, we maintain various different code paths, based on whether</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 56 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># the input requires gradients and whether it lays on the CPU/GPU.</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span><span style=\"font-weight: bold\">[</span>Rank:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span> FATAL ERROR :: MODULE:PT_BRIDGE Exception in Lowering thread<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">synStatus</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">[</span>Invalid argument<span style=\"font-weight: bold\">]</span> Node reshape  failed.\n",
       "Exception raised from add_node at <span style=\"color: #800080; text-decoration-color: #800080\">/npu-stack/pytorch-integration/backend/synapse_helpers/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">graph.cpp</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">463</span> <span style=\"font-weight: bold\">(</span>most recent\n",
       "call first<span style=\"font-weight: bold\">)</span>:\n",
       "frame #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">c10::E</span>rror::<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Error</span><span style=\"font-weight: bold\">(</span>c10::SourceLocation, std::__cxx<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11::ba</span>sic_string<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">char</span><span style=\"color: #000000; text-decoration-color: #000000\">, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::c</span><span style=\"color: #000000; text-decoration-color: #000000\">har_traits&lt;char&gt;, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;char&gt; &gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0xac</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0f6c64732c</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span><span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libc10.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">c10::de</span><span style=\"color: #000000; text-decoration-color: #000000\">tail::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torchCheckFail</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">char const*, char const*, unsigned int, std::__cxx</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11::ba</span><span style=\"color: #000000; text-decoration-color: #000000\">sic_string&lt;char, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::c</span><span style=\"color: #000000; text-decoration-color: #000000\">har_traits&lt;char&gt;, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;char&gt; &gt; const&amp;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0xf3</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0f6c5f061f</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libc10.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000000; text-decoration-color: #000000\">: synapse_helpers::graph::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">add_node</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">std::vector&lt;internalTensor*, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;internalTensor*&gt; &gt;&amp;&amp;, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">std::vector&lt;internalTensor*, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;internalTensor*&gt; &gt;&amp;&amp;, void*, unsigned int, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">std::__cxx</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11::ba</span><span style=\"color: #000000; text-decoration-color: #000000\">sic_string&lt;char, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::c</span><span style=\"color: #000000; text-decoration-color: #000000\">har_traits&lt;char&gt;, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;char&gt; &gt; const&amp;, unsigned long*, char </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">const**, char const**, bool, std::__cxx</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">11::ba</span><span style=\"color: #000000; text-decoration-color: #000000\">sic_string&lt;char, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::c</span><span style=\"color: #000000; text-decoration-color: #000000\">har_traits&lt;char&gt;, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;char&gt; &gt; </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">const&amp;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x21f3</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e9727b673</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000000; text-decoration-color: #000000\">: habana::OpBacken</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::B</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">uildNode</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">habana::OpBackend*, synapse_helpers::graph&amp;, habana::NodeAttr&amp;&amp;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x881</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e974a1a11</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000000; text-decoration-color: #000000\">: habana::OpBacken</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::B</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">uildReshape</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">habana::OpBackend*, synapse_helpers::graph&amp;, internalTensor*, </span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">c10::A</span><span style=\"color: #000000; text-decoration-color: #000000\">rrayRef&lt;long&gt;, c10::ScalarType, std::optional&lt;int&gt;, std::optional&lt;unsigned int&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x2fa</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e974a891a</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #000000; text-decoration-color: #000000\">: &lt;unknown function&gt; + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x126349d</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e9733e49d</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #000000; text-decoration-color: #000000\">: haban</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">a::Ba</span><span style=\"color: #000000; text-decoration-color: #000000\">tchNormOpBacken</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::Add</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Node</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">synapse_helpers::graph&amp;, std::vector&lt;c10::IValue, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;c10::IValue&gt; &gt; const&amp;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x228</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e97343b18</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"color: #000000; text-decoration-color: #000000\">: habana::HabanaLaunchOpPT::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BuildSynapseGraph</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">std::shared_ptr&lt;synapse_helpers::graph&gt;&amp;, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">habana::SynBuildCache&amp;, bool</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x24f1</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e97aabda1</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"color: #000000; text-decoration-color: #000000\">: habana::HabanaLaunchOpPT::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">run</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">std::vector&lt;c10::IValue, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;c10::IValue&gt; &gt;&amp;, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">std::optional&lt;std::vector&lt;at::Tensor, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;at::Tensor&gt; &gt; &gt;, std::optional&lt;std::vector&lt;std::vector&lt;long, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;long&gt; &gt;, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;std::vector&lt;long, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;long&gt; &gt; &gt; &gt; &gt;, bool, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">habana::HabanaLaunchOpPipeline::PipelineCallBase&amp;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x2ee8</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e97aca728</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"color: #000000; text-decoration-color: #000000\">: habana::HabanaLaunchOpPipeline::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoweringTask</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">std::unique_ptr&lt;habana::HabanaLaunchOpPT, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::defa</span><span style=\"color: #000000; text-decoration-color: #000000\">ult_delete&lt;habana::HabanaLaunchOpPT&gt; &gt;&amp;&amp;, std::vector&lt;c10::IValue, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;c10::IValue&gt; &gt;&amp;, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">std::optional&lt;std::vector&lt;at::Tensor, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;at::Tensor&gt; &gt; &gt;, std::optional&lt;std::vector&lt;std::vector&lt;long, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;long&gt; &gt;, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;std::vector&lt;long, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;long&gt; &gt; &gt; &gt; &gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0xda</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e97acb88a</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch_backend.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"color: #000000; text-decoration-color: #000000\">: haban</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">a::ea</span><span style=\"color: #000000; text-decoration-color: #000000\">ger::EagerExec::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">launch</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">()</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0xd22</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e98cd3362</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch2_plugin.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span><span style=\"color: #000000; text-decoration-color: #000000\">: haban</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">a::ea</span><span style=\"color: #000000; text-decoration-color: #000000\">ger::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EagerLoweringTask</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">c10::Symbol, std::vector&lt;c10::IValue, st</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">d::a</span><span style=\"color: #000000; text-decoration-color: #000000\">llocator&lt;c10::IValue&gt; &gt;&amp;&amp;, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">haban</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">a::ea</span><span style=\"color: #000000; text-decoration-color: #000000\">ger::OutputSpecsOrTensors&amp;&amp;, haban</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">a::ea</span><span style=\"color: #000000; text-decoration-color: #000000\">ger::EagerOpMetaData&amp;&amp;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x1c5</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e98c02545</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch2_plugin.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"color: #000000; text-decoration-color: #000000\">: habana_helpers::ThreadPoolBase&lt;habana_helpers::BlockingQueue, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">habana_helpers::move_only_function_void&gt;::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">executePendingTask</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">habana_helpers::move_only_function_void&amp;&amp;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x72</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e990648c2</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch2_plugin.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"color: #000000; text-decoration-color: #000000\">: habana_helpers::ThreadPoolBase&lt;habana_helpers::BlockingQueue, </span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">habana_helpers::move_only_function_void&gt;::</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">main_loop</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">()</span><span style=\"color: #000000; text-decoration-color: #000000\"> + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0xbe</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0e990650be</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libhabana_pytorch2_plugin.so</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"color: #000000; text-decoration-color: #000000\">: &lt;unknown function&gt; + </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0xdc253</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0f77e29253</span><span style=\"color: #000000; text-decoration-color: #000000\"> in </span><span style=\"color: #800080; text-decoration-color: #800080\">/lib/x86_64-linux-gnu/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libstdc++.so.6</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">frame #</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"color: #000000; text-decoration-color: #000000\">: &lt;unknown function</span><span style=\"font-weight: bold\">&gt;</span> + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x94ac3</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0f787b1ac3</span> in <span style=\"color: #800080; text-decoration-color: #800080\">/lib/x86_64-linux-gnu/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libc.so.6</span><span style=\"font-weight: bold\">)</span>\n",
       "frame #<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>: clone + <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x44</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7f0f78842a04</span> in <span style=\"color: #800080; text-decoration-color: #800080\">/lib/x86_64-linux-gnu/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">libc.so.6</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m48\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m45 \u001b[0m\u001b[2m│   \u001b[0mtrain_loss = train(epoch)                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m torch.inference_mode():                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m│   │   \u001b[0mmodel.eval()                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m48 \u001b[2m│   │   \u001b[0mtrain_acc = test(train_loader)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m│   │   \u001b[0mtest_acc = test(test_loader)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mEpoch: \u001b[0m\u001b[33m{:03d}\u001b[0m\u001b[33m, Train Loss: \u001b[0m\u001b[33m{:.7f}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mTrain Acc: \u001b[0m\u001b[33m{:.7f}\u001b[0m\u001b[33m, Test Acc: \u001b[0m\u001b[33m{:.7f}\u001b[0m\u001b[33m'\u001b[0m.format(epoch, train_loss,                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtest\u001b[0m:\u001b[94m35\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m│   \u001b[0mcorrect = \u001b[94m0\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m data \u001b[95min\u001b[0m loader:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   │   \u001b[0mdata = data.to(device)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m35 \u001b[2m│   │   \u001b[0moutput = model(data.x, data.edge_index, data.batch)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   \u001b[0mpred = output.max(dim=\u001b[94m1\u001b[0m)[\u001b[94m1\u001b[0m]                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   \u001b[0mcorrect += pred.eq(data.y).sum().item()                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m correct / \u001b[96mlen\u001b[0m(loader.dataset)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1556\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1553 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1554 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1555 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1556 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1557 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1558 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_call_impl\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1559 \u001b[0m\u001b[2m│   │   \u001b[0mforward_call = (\u001b[96mself\u001b[0m._slow_forward \u001b[94mif\u001b[0m torch._C._get_tracing_state() \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.fo  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1565\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1562 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1563 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1565 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1566 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1567 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1568 \u001b[0m\u001b[2m│   │   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m35\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m32 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, x, edge_index, batch):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m33 \u001b[0m\u001b[2m│   │   \u001b[0mx = F.relu(\u001b[96mself\u001b[0m.conv1(x, edge_index))                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m34 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.bn1(x)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m35 \u001b[2m│   │   \u001b[0mx = F.relu(\u001b[96mself\u001b[0m.conv2(x, edge_index))                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.bn2(x)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   \u001b[0mx = F.relu(\u001b[96mself\u001b[0m.conv3(x, edge_index))                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m38 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.bn3(x)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1556\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1553 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1554 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1555 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1556 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1557 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1558 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_call_impl\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1559 \u001b[0m\u001b[2m│   │   \u001b[0mforward_call = (\u001b[96mself\u001b[0m._slow_forward \u001b[94mif\u001b[0m torch._C._get_tracing_state() \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.fo  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1565\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1562 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1563 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1565 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1566 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1567 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1568 \u001b[0m\u001b[2m│   │   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/\u001b[0m\u001b[1;33mgin_conv.py\u001b[0m:\u001b[94m84\u001b[0m in \u001b[92mforward\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   │   │   \u001b[0mx = (x, x)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 82 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 83 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# propagate_type: (x: OptPairTensor)\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 84 \u001b[2m│   │   \u001b[0mout = \u001b[96mself\u001b[0m.propagate(edge_index, x=x, size=size)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 85 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 86 \u001b[0m\u001b[2m│   │   \u001b[0mx_r = x[\u001b[94m1\u001b[0m]                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 87 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m x_r \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/\u001b[0m\u001b[1;33mmessage_passing.py\u001b[0m:\u001b[94m541\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpropagate\u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 538 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m res \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 539 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0maggr_kwargs = res[\u001b[94m0\u001b[0m] \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(res, \u001b[96mtuple\u001b[0m) \u001b[94melse\u001b[0m res           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 540 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 541 \u001b[2m│   │   │   │   \u001b[0mout = \u001b[96mself\u001b[0m.aggregate(out, **aggr_kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 542 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 543 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m hook \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._aggregate_forward_hooks.values():                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 544 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mres = hook(\u001b[96mself\u001b[0m, (aggr_kwargs, ), out)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92maggregate\u001b[0m:\u001b[94m11\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92maggregate\u001b[0m(\u001b[96mself\u001b[0m, inputs, index):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0mx = torch.sigmoid(inputs)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m11 \u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.laf(x, index)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0mx = x.view((-\u001b[94m1\u001b[0m, \u001b[96mself\u001b[0m.dim * \u001b[96mself\u001b[0m.units))                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0mx = \u001b[96mself\u001b[0m.mlp(x)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m x                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1556\u001b[0m in \u001b[92m_wrapped_call_impl\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1553 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1554 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._compiled_call_impl(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1555 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1556 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_impl(*args, **kwargs)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1557 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1558 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_call_impl\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1559 \u001b[0m\u001b[2m│   │   \u001b[0mforward_call = (\u001b[96mself\u001b[0m._slow_forward \u001b[94mif\u001b[0m torch._C._get_tracing_state() \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.fo  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1565\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1562 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1563 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1564 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1565 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1566 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1567 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1568 \u001b[0m\u001b[2m│   │   │   \u001b[0mresult = \u001b[94mNone\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mforward\u001b[0m:\u001b[94m82\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# scatter = scatter_add(exps, index.view(-1), dim=dim)\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 82 \u001b[2m│   │   \u001b[0mscatter_res = scatter(exps, index, dim=dim, reduce=\u001b[33m'\u001b[0m\u001b[33msum\u001b[0m\u001b[33m'\u001b[0m)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 83 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 84 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# size = torch.tensor(exps.size())\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 85 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# size[dim] = index.max() + 1\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/\u001b[0m\u001b[1;33m_scatter.py\u001b[0m:\u001b[94m53\u001b[0m in \u001b[92mscatter\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   │   │   │   │   │   │    \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0msrc.dim()\u001b[90m \u001b[0m-\u001b[90m \u001b[0m\u001b[94m1\u001b[0m\u001b[33m}\u001b[0m\u001b[33m (got \u001b[0m\u001b[33m{\u001b[0mdim\u001b[33m}\u001b[0m\u001b[33m)\u001b[0m\u001b[33m\"\u001b[0m)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m dim_size \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 53 \u001b[2m│   │   │   \u001b[0mdim_size = \u001b[96mint\u001b[0m(index.max()) + \u001b[94m1\u001b[0m \u001b[94mif\u001b[0m index.numel() > \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m \u001b[94m0\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# For now, we maintain various different code paths, based on whether\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# the input requires gradients and whether it lays on the CPU/GPU.\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0m\u001b[1m[\u001b[0mRank:\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m FATAL ERROR :: MODULE:PT_BRIDGE Exception in Lowering thread\u001b[33m...\u001b[0m\n",
       "\u001b[33msynStatus\u001b[0m=\u001b[1;36m1\u001b[0m \u001b[1m[\u001b[0mInvalid argument\u001b[1m]\u001b[0m Node reshape  failed.\n",
       "Exception raised from add_node at \u001b[35m/npu-stack/pytorch-integration/backend/synapse_helpers/\u001b[0m\u001b[95mgraph.cpp\u001b[0m:\u001b[1;36m463\u001b[0m \u001b[1m(\u001b[0mmost recent\n",
       "call first\u001b[1m)\u001b[0m:\n",
       "frame #\u001b[1;36m0\u001b[0m: \u001b[1;92mc10::E\u001b[0mrror::\u001b[1;35mError\u001b[0m\u001b[1m(\u001b[0mc10::SourceLocation, std::__cxx\u001b[1;92m11::ba\u001b[0msic_string\u001b[1m<\u001b[0m\u001b[1;95mchar\u001b[0m\u001b[39m, st\u001b[0m\u001b[1;92md::c\u001b[0m\u001b[39mhar_traits<char>, \u001b[0m\n",
       "\u001b[39mst\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<char> >\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0xac\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0f6c64732c\u001b[0m\u001b[39m in \u001b[0m\u001b[35m/usr/local/lib/python3.10/dist-packages/torch/lib/\u001b[0m\u001b[95mlibc10.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m: \u001b[0m\u001b[1;92mc10::de\u001b[0m\u001b[39mtail::\u001b[0m\u001b[1;35mtorchCheckFail\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mchar const*, char const*, unsigned int, std::__cxx\u001b[0m\u001b[1;92m11::ba\u001b[0m\u001b[39msic_string<char, \u001b[0m\n",
       "\u001b[39mst\u001b[0m\u001b[1;92md::c\u001b[0m\u001b[39mhar_traits<char>, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<char> > const&\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0xf3\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0f6c5f061f\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/torch/lib/\u001b[0m\u001b[95mlibc10.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m: synapse_helpers::graph::\u001b[0m\u001b[1;35madd_node\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mstd::vector<internalTensor*, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<internalTensor*> >&&, \u001b[0m\n",
       "\u001b[39mstd::vector<internalTensor*, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<internalTensor*> >&&, void*, unsigned int, \u001b[0m\n",
       "\u001b[39mstd::__cxx\u001b[0m\u001b[1;92m11::ba\u001b[0m\u001b[39msic_string<char, st\u001b[0m\u001b[1;92md::c\u001b[0m\u001b[39mhar_traits<char>, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<char> > const&, unsigned long*, char \u001b[0m\n",
       "\u001b[39mconst**, char const**, bool, std::__cxx\u001b[0m\u001b[1;92m11::ba\u001b[0m\u001b[39msic_string<char, st\u001b[0m\u001b[1;92md::c\u001b[0m\u001b[39mhar_traits<char>, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<char> > \u001b[0m\n",
       "\u001b[39mconst&\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x21f3\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e9727b673\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m: habana::OpBacken\u001b[0m\u001b[1;92md::B\u001b[0m\u001b[1;35muildNode\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mhabana::OpBackend*, synapse_helpers::graph&, habana::NodeAttr&&\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x881\u001b[0m\u001b[39m \u001b[0m\n",
       "\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e974a1a11\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m: habana::OpBacken\u001b[0m\u001b[1;92md::B\u001b[0m\u001b[1;35muildReshape\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mhabana::OpBackend*, synapse_helpers::graph&, internalTensor*, \u001b[0m\n",
       "\u001b[1;92mc10::A\u001b[0m\u001b[39mrrayRef<long>, c10::ScalarType, std::optional<int>, std::optional<unsigned int>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x2fa\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e974a891a\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m: <unknown function> + \u001b[0m\u001b[1;36m0x126349d\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e9733e49d\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m6\u001b[0m\u001b[39m: haban\u001b[0m\u001b[1;92ma::Ba\u001b[0m\u001b[39mtchNormOpBacken\u001b[0m\u001b[1;92md::Add\u001b[0m\u001b[1;35mNode\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39msynapse_helpers::graph&, std::vector<c10::IValue, \u001b[0m\n",
       "\u001b[39mst\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<c10::IValue> > const&\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x228\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e97343b18\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m7\u001b[0m\u001b[39m: habana::HabanaLaunchOpPT::\u001b[0m\u001b[1;35mBuildSynapseGraph\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mstd::shared_ptr<synapse_helpers::graph>&, \u001b[0m\n",
       "\u001b[39mhabana::SynBuildCache&, bool\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x24f1\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e97aabda1\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m8\u001b[0m\u001b[39m: habana::HabanaLaunchOpPT::\u001b[0m\u001b[1;35mrun\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mstd::vector<c10::IValue, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<c10::IValue> >&, \u001b[0m\n",
       "\u001b[39mstd::optional<std::vector<at::Tensor, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<at::Tensor> > >, std::optional<std::vector<std::vector<long, \u001b[0m\n",
       "\u001b[39mst\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<long> >, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<std::vector<long, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<long> > > > >, bool, \u001b[0m\n",
       "\u001b[39mhabana::HabanaLaunchOpPipeline::PipelineCallBase&\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x2ee8\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e97aca728\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m9\u001b[0m\u001b[39m: habana::HabanaLaunchOpPipeline::\u001b[0m\u001b[1;35mLoweringTask\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mstd::unique_ptr<habana::HabanaLaunchOpPT, \u001b[0m\n",
       "\u001b[39mst\u001b[0m\u001b[1;92md::defa\u001b[0m\u001b[39mult_delete<habana::HabanaLaunchOpPT> >&&, std::vector<c10::IValue, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<c10::IValue> >&, \u001b[0m\n",
       "\u001b[39mstd::optional<std::vector<at::Tensor, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<at::Tensor> > >, std::optional<std::vector<std::vector<long, \u001b[0m\n",
       "\u001b[39mst\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<long> >, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<std::vector<long, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<long> > > > >\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0xda\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e97acb88a\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch_backend.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m10\u001b[0m\u001b[39m: haban\u001b[0m\u001b[1;92ma::ea\u001b[0m\u001b[39mger::EagerExec::\u001b[0m\u001b[1;35mlaunch\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0xd22\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e98cd3362\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch2_plugin.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m11\u001b[0m\u001b[39m: haban\u001b[0m\u001b[1;92ma::ea\u001b[0m\u001b[39mger::\u001b[0m\u001b[1;35mEagerLoweringTask\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mc10::Symbol, std::vector<c10::IValue, st\u001b[0m\u001b[1;92md::a\u001b[0m\u001b[39mllocator<c10::IValue> >&&, \u001b[0m\n",
       "\u001b[39mhaban\u001b[0m\u001b[1;92ma::ea\u001b[0m\u001b[39mger::OutputSpecsOrTensors&&, haban\u001b[0m\u001b[1;92ma::ea\u001b[0m\u001b[39mger::EagerOpMetaData&&\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x1c5\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e98c02545\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch2_plugin.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m12\u001b[0m\u001b[39m: habana_helpers::ThreadPoolBase<habana_helpers::BlockingQueue, \u001b[0m\n",
       "\u001b[39mhabana_helpers::move_only_function_void>::\u001b[0m\u001b[1;35mexecutePendingTask\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mhabana_helpers::move_only_function_void&&\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0x72\u001b[0m\u001b[39m \u001b[0m\n",
       "\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e990648c2\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch2_plugin.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m13\u001b[0m\u001b[39m: habana_helpers::ThreadPoolBase<habana_helpers::BlockingQueue, \u001b[0m\n",
       "\u001b[39mhabana_helpers::move_only_function_void>::\u001b[0m\u001b[1;35mmain_loop\u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m + \u001b[0m\u001b[1;36m0xbe\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0e990650be\u001b[0m\u001b[39m in \u001b[0m\n",
       "\u001b[35m/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/lib/\u001b[0m\u001b[95mlibhabana_pytorch2_plugin.so\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m14\u001b[0m\u001b[39m: <unknown function> + \u001b[0m\u001b[1;36m0xdc253\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[1;36m0x7f0f77e29253\u001b[0m\u001b[39m in \u001b[0m\u001b[35m/lib/x86_64-linux-gnu/\u001b[0m\u001b[95mlibstdc++.so.6\u001b[0m\u001b[1;39m)\u001b[0m\n",
       "\u001b[39mframe #\u001b[0m\u001b[1;36m15\u001b[0m\u001b[39m: <unknown function\u001b[0m\u001b[1m>\u001b[0m + \u001b[1;36m0x94ac3\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m0x7f0f787b1ac3\u001b[0m in \u001b[35m/lib/x86_64-linux-gnu/\u001b[0m\u001b[95mlibc.so.6\u001b[0m\u001b[1m)\u001b[0m\n",
       "frame #\u001b[1;36m16\u001b[0m: clone + \u001b[1;36m0x44\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m0x7f0f78842a04\u001b[0m in \u001b[35m/lib/x86_64-linux-gnu/\u001b[0m\u001b[95mlibc.so.6\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import traceback\n",
    "traceback.install()\n",
    "\n",
    "# device = torch.device(\"hpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "net = \"LAF\"\n",
    "if net == \"LAF\":\n",
    "    model = LAFNet().to(device)\n",
    "elif net == \"PNA\":\n",
    "    model = PNANet().to(device)\n",
    "elif net == \"GIN\":\n",
    "    model = GINNet().to(device)\n",
    "\n",
    "def train(epoch):\n",
    "    if epoch == 51:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.5 * param_group['lr']\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(output, data.y)        \n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "model.train()\n",
    "# model = torch.compile(model, backend=\"hpu_backend\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1, 101):    \n",
    "    train_loss = train(epoch)    \n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        train_acc = test(train_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        print('Epoch: {:03d}, Train Loss: {:.7f}, '\n",
    "            'Train Acc: {:.7f}, Test Acc: {:.7f}'.format(epoch, train_loss,\n",
    "                                                        train_acc, test_acc))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
