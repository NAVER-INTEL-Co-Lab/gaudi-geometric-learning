{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT_HPU_LAZY_MODE: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling add_step_closure function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
      "Calling mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n",
      "Calling iter_mark_step function does not have any effect. It's lazy mode only functionality. (warning logged once)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0a0+git74cd574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/inspect.py:288: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(object, types.FunctionType)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the eager mode\n",
    "os.environ['PT_HPU_LAZY_MODE'] = '0'\n",
    "\n",
    "# Verify the environment variable is set\n",
    "print(f\"PT_HPU_LAZY_MODE: {os.environ['PT_HPU_LAZY_MODE']}\")\n",
    "\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "import habana_frameworks.torch.core as htcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.datasets import AMiner\n",
    "from torch_geometric.nn import MetaPath2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaPath2Vec\n",
    "\n",
    "[paper](https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf)  \n",
    "[code](https://github.com/rusty1s/pytorch_geometric/blob/master/examples/metapath2vec.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"hpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 0\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_CACHE_FOLDER_DELETE = 0\n",
      " PT_HPU_RECIPE_CACHE_CONFIG = \n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      " PT_HPU_EAGER_PIPELINE_ENABLE = 1\n",
      " PT_HPU_EAGER_COLLECTIVE_PIPELINE_ENABLE = 1\n",
      "---------------------------: System Configuration :---------------------------\n",
      "Num CPU Cores : 160\n",
      "CPU RAM       : 2113407800 KB\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "path = osp.join('.', 'data', 'AMiner')\n",
    "dataset = AMiner(path)\n",
    "data = dataset[0]\n",
    "\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  author={\n",
      "    y=[246678],\n",
      "    y_index=[246678],\n",
      "    num_nodes=1693531,\n",
      "  },\n",
      "  venue={\n",
      "    y=[134],\n",
      "    y_index=[134],\n",
      "    num_nodes=3883,\n",
      "  },\n",
      "  paper={ num_nodes=3194405 },\n",
      "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
      "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
      "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
      "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "tensor([[      0,       1,       2,  ..., 3194404, 3194404, 3194404],\n",
      "        [      0,       1,       2,  ...,    4393,   21681,  317436]],\n",
      "       device='hpu:0')\n"
     ]
    }
   ],
   "source": [
    "print(type(data.edge_index_dict))\n",
    "print(data.edge_index_dict[('paper', 'written_by', 'author')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('paper', 'written_by', 'author'), ('author', 'writes', 'paper'), ('paper', 'published_in', 'venue'), ('venue', 'publishes', 'paper')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'author': 1693531, 'venue': 3883, 'paper': 3194405}\n"
     ]
    }
   ],
   "source": [
    "print(type(data.num_nodes_dict))\n",
    "print(data.num_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7], device='hpu:0')\n"
     ]
    }
   ],
   "source": [
    "print(type(data.y_dict))\n",
    "print(data.y_dict[\"venue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "tensor([1741, 2245,  111,  837, 2588, 2116, 2696, 3648, 3784,  313, 3414,  598,\n",
      "        2995, 2716, 1423,  783, 1902, 3132, 1753, 2748, 2660, 3182,  775, 3339,\n",
      "        1601, 3589,  156, 1145,  692, 3048,  925, 1587,  820, 1374, 3719,  819,\n",
      "         492, 3830, 2777, 3001, 3693,  517, 1808, 2353, 3499, 1763, 2372, 1030,\n",
      "         721, 2680, 3355, 1217, 3400, 1271, 1970, 1127,  407,  353, 1471, 1095,\n",
      "         477, 3701,   65, 1009, 1899, 1442, 2073, 3143, 2466,  289, 1996, 1070,\n",
      "        3871, 3695,  281, 3633,   50, 2642, 1925, 1285, 2587, 3814, 3582, 1873,\n",
      "        1339, 3450,  271, 2966,  453, 2638, 1354, 3211,  391, 1588, 3875, 2216,\n",
      "        2146, 3765, 2486,  661, 3367,  426,  750, 2158,  519,  230, 1677,  839,\n",
      "        2945, 1313, 1037, 2879, 2225, 3523, 1247,  448,  227, 3385,  529, 2849,\n",
      "        1584, 1229,  373, 2235, 1819, 1764, 3155, 2852, 2789, 3474, 1571, 2088,\n",
      "         208,  462], device='hpu:0')\n"
     ]
    }
   ],
   "source": [
    "print(type(data.y_index_dict))\n",
    "print(data.y_index_dict[\"venue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "\n",
    "# dict_keys([('paper', 'written_by', 'author'), ('author', 'writes', 'paper'), ('paper', 'published_in', 'venue'), ('venue', 'publishes', 'paper')])\n",
    "\n",
    "metapath = [\n",
    "    ('author', 'writes', 'paper'),\n",
    "    ('paper', 'published_in', 'venue'),\n",
    "    ('venue', 'publishes', 'paper'),\n",
    "    ('paper', 'written_by', 'author'),\n",
    "]\n",
    "\n",
    "\n",
    "model = MetaPath2Vec(data.edge_index_dict, \n",
    "                     embedding_dim=128,\n",
    "                     metapath=metapath,\n",
    "                     walk_length=5, \n",
    "                     context_size=3,\n",
    "                     walks_per_node=3,\n",
    "                     num_negative_samples=1,\n",
    "                    #  sparse=True,\n",
    "                     sparse=False,\n",
    "                    ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the loader to build a loader\n",
    "loader = model.loader(batch_size=128, shuffle=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "1 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "2 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "3 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "4 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "5 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "6 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "7 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "8 torch.Size([1536, 3]) torch.Size([1536, 3])\n",
      "9 torch.Size([1536, 3]) torch.Size([1536, 3])\n"
     ]
    }
   ],
   "source": [
    "for idx, (pos_rw, neg_rw) in enumerate(loader):\n",
    "    if idx == 10: break\n",
    "    print(idx, pos_rw.shape, neg_rw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1639018, 4891819, 4891819]) tensor([1639018, 4741022, 4891387])\n"
     ]
    }
   ],
   "source": [
    "print(pos_rw[0],neg_rw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizialize optimizer\n",
    "# optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, log_steps=500, eval_steps=1000):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
    "            total_loss = 0\n",
    "\n",
    "        if (i + 1) % eval_steps == 0:\n",
    "            acc = test()\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Acc: {acc:.4f}'))\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(train_ratio=0.1):\n",
    "    model.eval()\n",
    "\n",
    "    z = model('author', batch=data.y_index_dict['author'])\n",
    "    y = data.y_dict['author']\n",
    "\n",
    "    perm = torch.randperm(z.size(0), device=z.device)\n",
    "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
    "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
    "\n",
    "    return model.test(z[train_perm], y[train_perm], z[test_perm],\n",
    "                      y[test_perm], max_iter=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 00500/13231, Loss: 6.4062\n",
      "Epoch: 1, Step: 01000/13231, Loss: 6.4185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/jit/_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 01000/13231, Acc: 0.2770\n",
      "Epoch: 1, Step: 01500/13231, Loss: 6.4084\n",
      "Epoch: 1, Step: 02000/13231, Loss: 6.4046\n",
      "Epoch: 1, Step: 02000/13231, Acc: 0.2760\n",
      "Epoch: 1, Step: 02500/13231, Loss: 6.4046\n",
      "Epoch: 1, Step: 03000/13231, Loss: 6.4007\n",
      "Epoch: 1, Step: 03000/13231, Acc: 0.2757\n",
      "Epoch: 1, Step: 03500/13231, Loss: 6.4095\n",
      "Epoch: 1, Step: 04000/13231, Loss: 6.4061\n",
      "Epoch: 1, Step: 04000/13231, Acc: 0.2759\n",
      "Epoch: 1, Step: 04500/13231, Loss: 6.4176\n",
      "Epoch: 1, Step: 05000/13231, Loss: 6.4154\n",
      "Epoch: 1, Step: 05000/13231, Acc: 0.2762\n",
      "Epoch: 1, Step: 05500/13231, Loss: 6.4110\n",
      "Epoch: 1, Step: 06000/13231, Loss: 6.4030\n",
      "Epoch: 1, Step: 06000/13231, Acc: 0.2748\n",
      "Epoch: 1, Step: 06500/13231, Loss: 6.4308\n",
      "Epoch: 1, Step: 07000/13231, Loss: 6.4115\n",
      "Epoch: 1, Step: 07000/13231, Acc: 0.2768\n",
      "Epoch: 1, Step: 07500/13231, Loss: 6.3976\n",
      "Epoch: 1, Step: 08000/13231, Loss: 6.4083\n",
      "Epoch: 1, Step: 08000/13231, Acc: 0.2759\n",
      "Epoch: 1, Step: 08500/13231, Loss: 6.4126\n",
      "Epoch: 1, Step: 09000/13231, Loss: 6.4040\n",
      "Epoch: 1, Step: 09000/13231, Acc: 0.2770\n",
      "Epoch: 1, Step: 09500/13231, Loss: 6.4039\n",
      "Epoch: 1, Step: 10000/13231, Loss: 6.4184\n",
      "Epoch: 1, Step: 10000/13231, Acc: 0.2757\n",
      "Epoch: 1, Step: 10500/13231, Loss: 6.4029\n",
      "Epoch: 1, Step: 11000/13231, Loss: 6.4286\n",
      "Epoch: 1, Step: 11000/13231, Acc: 0.2770\n",
      "Epoch: 1, Step: 11500/13231, Loss: 6.4070\n",
      "Epoch: 1, Step: 12000/13231, Loss: 6.4062\n",
      "Epoch: 1, Step: 12000/13231, Acc: 0.2761\n",
      "Epoch: 1, Step: 12500/13231, Loss: 6.4231\n",
      "Epoch: 1, Step: 13000/13231, Loss: 6.4006\n",
      "Epoch: 1, Step: 13000/13231, Acc: 0.2769\n",
      "Epoch: 1, Accuracy: 0.2759\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model = torch.compile(model, backend=\"hpu_backend\")\n",
    "for epoch in range(1, 2):\n",
    "    train(epoch)\n",
    "    acc = test()\n",
    "    print(f'Epoch: {epoch}, Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to \"mymodel\"\n",
    "\n",
    "torch.save(model.state_dict(), \"mymodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_orig_mod.embedding.weight',\n",
       "              tensor([[ 1.0630,  0.1488, -0.1911,  ...,  1.5862,  1.5311, -2.1510],\n",
       "                      [ 0.1243,  1.2492,  1.2393,  ...,  0.2227,  2.1340, -0.1600],\n",
       "                      [ 1.4810,  0.7495,  0.4144,  ..., -1.2538,  1.9429,  0.6207],\n",
       "                      ...,\n",
       "                      [-1.3474, -0.3566, -1.2574,  ...,  0.4756, -0.4529, -0.1462],\n",
       "                      [-0.9339, -0.2493, -1.7788,  ..., -0.0246,  1.1848,  0.1878],\n",
       "                      [ 1.0832, -0.6992,  0.2164,  ..., -2.0589,  1.1881,  0.4817]],\n",
       "                     device='hpu:0'))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = MetaPath2Vec(data.edge_index_dict, \n",
    "                     embedding_dim=128,\n",
    "                     metapath=metapath,\n",
    "                     walk_length=5, \n",
    "                     context_size=3,\n",
    "                     walks_per_node=3,\n",
    "                     num_negative_samples=1,\n",
    "                    #  sparse=True,\n",
    "                     sparse=False,\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0402, 0.4621, 0.4585, 0.4498, 0.5106], device='hpu:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.embedding.weight[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2511787/261134530.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_file = torch.load(\"mymodel\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('_orig_mod.embedding.weight', tensor([[ 1.0630,  0.1488, -0.1911,  ...,  1.5862,  1.5311, -2.1510],\n",
      "        [ 0.1243,  1.2492,  1.2393,  ...,  0.2227,  2.1340, -0.1600],\n",
      "        [ 1.4810,  0.7495,  0.4144,  ..., -1.2538,  1.9429,  0.6207],\n",
      "        ...,\n",
      "        [-1.3474, -0.3566, -1.2574,  ...,  0.4756, -0.4529, -0.1462],\n",
      "        [-0.9339, -0.2493, -1.7788,  ..., -0.0246,  1.1848,  0.1878],\n",
      "        [ 1.0832, -0.6992,  0.2164,  ..., -2.0589,  1.1881,  0.4817]],\n",
      "       device='hpu:0'))])\n"
     ]
    }
   ],
   "source": [
    "loaded_file = torch.load(\"mymodel\")\n",
    "print(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0630,  0.1488, -0.1911,  ...,  1.5862,  1.5311, -2.1510],\n",
       "        [ 0.1243,  1.2492,  1.2393,  ...,  0.2227,  2.1340, -0.1600],\n",
       "        [ 1.4810,  0.7495,  0.4144,  ..., -1.2538,  1.9429,  0.6207],\n",
       "        ...,\n",
       "        [-1.3474, -0.3566, -1.2574,  ...,  0.4756, -0.4529, -0.1462],\n",
       "        [-0.9339, -0.2493, -1.7788,  ..., -0.0246,  1.1848,  0.1878],\n",
       "        [ 1.0832, -0.6992,  0.2164,  ..., -2.0589,  1.1881,  0.4817]],\n",
       "       device='hpu:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_file['_orig_mod.embedding.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "# loaded_model.load_state_dict(torch.load(\"mymodel\").detach().cpu())\n",
    "loaded_model.embedding.weight = torch.nn.Parameter(loaded_file['_orig_mod.embedding.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1243,  1.2492,  1.2393,  0.1696, -0.9190], device='hpu:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.embedding.weight[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_venue = loaded_model('venue', batch=data.y_index_dict['venue']).cpu().detach().numpy()\n",
    "z_auth = loaded_model('author', batch=data.y_index_dict['author']).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_venue = z_venue[0:100]\n",
    "z_auth = z_auth[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  author={\n",
       "    y=[246678],\n",
       "    y_index=[246678],\n",
       "    num_nodes=1693531,\n",
       "  },\n",
       "  venue={\n",
       "    y=[134],\n",
       "    y_index=[134],\n",
       "    num_nodes=3883,\n",
       "  },\n",
       "  paper={ num_nodes=3194405 },\n",
       "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
       "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
       "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
       "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  author={\n",
       "    y=[246678],\n",
       "    y_index=[246678],\n",
       "    num_nodes=1693531,\n",
       "  },\n",
       "  venue={\n",
       "    y=[134],\n",
       "    y_index=[134],\n",
       "    num_nodes=3883,\n",
       "  },\n",
       "  paper={ num_nodes=3194405 },\n",
       "  (paper, written_by, author)={ edge_index=[2, 9323605] },\n",
       "  (author, writes, paper)={ edge_index=[2, 9323605] },\n",
       "  (paper, published_in, venue)={ edge_index=[2, 3194405] },\n",
       "  (venue, publishes, paper)={ edge_index=[2, 3194405] }\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
